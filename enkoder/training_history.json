[
    {
        "loss": 0.6792,
        "grad_norm": 0.9638351202011108,
        "learning_rate": 1.99250936329588e-05,
        "epoch": 0.018726591760299626,
        "step": 10
    },
    {
        "loss": 0.7168,
        "grad_norm": 1.045677900314331,
        "learning_rate": 1.9850187265917604e-05,
        "epoch": 0.03745318352059925,
        "step": 20
    },
    {
        "loss": 0.6881,
        "grad_norm": 1.6907180547714233,
        "learning_rate": 1.9775280898876404e-05,
        "epoch": 0.056179775280898875,
        "step": 30
    },
    {
        "loss": 0.645,
        "grad_norm": 3.298081636428833,
        "learning_rate": 1.9700374531835207e-05,
        "epoch": 0.0749063670411985,
        "step": 40
    },
    {
        "loss": 0.4941,
        "grad_norm": 12.697548866271973,
        "learning_rate": 1.9625468164794007e-05,
        "epoch": 0.09363295880149813,
        "step": 50
    },
    {
        "loss": 0.5416,
        "grad_norm": 12.158525466918945,
        "learning_rate": 1.955056179775281e-05,
        "epoch": 0.11235955056179775,
        "step": 60
    },
    {
        "loss": 0.5008,
        "grad_norm": 13.43736743927002,
        "learning_rate": 1.9475655430711613e-05,
        "epoch": 0.13108614232209737,
        "step": 70
    },
    {
        "loss": 0.477,
        "grad_norm": 43.16585159301758,
        "learning_rate": 1.9400749063670416e-05,
        "epoch": 0.149812734082397,
        "step": 80
    },
    {
        "loss": 0.4618,
        "grad_norm": 13.191268920898438,
        "learning_rate": 1.9325842696629215e-05,
        "epoch": 0.16853932584269662,
        "step": 90
    },
    {
        "loss": 0.5076,
        "grad_norm": 24.253787994384766,
        "learning_rate": 1.925093632958802e-05,
        "epoch": 0.18726591760299627,
        "step": 100
    },
    {
        "loss": 0.3858,
        "grad_norm": 2.507230043411255,
        "learning_rate": 1.9176029962546818e-05,
        "epoch": 0.20599250936329588,
        "step": 110
    },
    {
        "loss": 0.4043,
        "grad_norm": 9.795863151550293,
        "learning_rate": 1.910112359550562e-05,
        "epoch": 0.2247191011235955,
        "step": 120
    },
    {
        "loss": 0.4065,
        "grad_norm": 20.330646514892578,
        "learning_rate": 1.902621722846442e-05,
        "epoch": 0.24344569288389514,
        "step": 130
    },
    {
        "loss": 0.4144,
        "grad_norm": 10.881498336791992,
        "learning_rate": 1.8951310861423224e-05,
        "epoch": 0.26217228464419473,
        "step": 140
    },
    {
        "loss": 0.3337,
        "grad_norm": 28.57782554626465,
        "learning_rate": 1.8876404494382024e-05,
        "epoch": 0.2808988764044944,
        "step": 150
    },
    {
        "loss": 0.4061,
        "grad_norm": 5.960277080535889,
        "learning_rate": 1.8801498127340823e-05,
        "epoch": 0.299625468164794,
        "step": 160
    },
    {
        "loss": 0.3942,
        "grad_norm": 14.324618339538574,
        "learning_rate": 1.8726591760299626e-05,
        "epoch": 0.31835205992509363,
        "step": 170
    },
    {
        "loss": 0.3977,
        "grad_norm": 5.813459873199463,
        "learning_rate": 1.8651685393258426e-05,
        "epoch": 0.33707865168539325,
        "step": 180
    },
    {
        "loss": 0.3695,
        "grad_norm": 14.074766159057617,
        "learning_rate": 1.8576779026217232e-05,
        "epoch": 0.35580524344569286,
        "step": 190
    },
    {
        "loss": 0.2775,
        "grad_norm": 27.58814239501953,
        "learning_rate": 1.8501872659176032e-05,
        "epoch": 0.37453183520599254,
        "step": 200
    },
    {
        "loss": 0.4139,
        "grad_norm": 2.569944381713867,
        "learning_rate": 1.8426966292134835e-05,
        "epoch": 0.39325842696629215,
        "step": 210
    },
    {
        "loss": 0.4078,
        "grad_norm": 17.906082153320312,
        "learning_rate": 1.8352059925093635e-05,
        "epoch": 0.41198501872659177,
        "step": 220
    },
    {
        "loss": 0.4031,
        "grad_norm": 8.406447410583496,
        "learning_rate": 1.8277153558052438e-05,
        "epoch": 0.4307116104868914,
        "step": 230
    },
    {
        "loss": 0.2922,
        "grad_norm": 8.281682968139648,
        "learning_rate": 1.8202247191011237e-05,
        "epoch": 0.449438202247191,
        "step": 240
    },
    {
        "loss": 0.3589,
        "grad_norm": 5.367426872253418,
        "learning_rate": 1.812734082397004e-05,
        "epoch": 0.4681647940074906,
        "step": 250
    },
    {
        "loss": 0.3762,
        "grad_norm": 10.382508277893066,
        "learning_rate": 1.805243445692884e-05,
        "epoch": 0.4868913857677903,
        "step": 260
    },
    {
        "loss": 0.4696,
        "grad_norm": 9.67580795288086,
        "learning_rate": 1.7977528089887643e-05,
        "epoch": 0.5056179775280899,
        "step": 270
    },
    {
        "loss": 0.39,
        "grad_norm": 11.256088256835938,
        "learning_rate": 1.7902621722846443e-05,
        "epoch": 0.5243445692883895,
        "step": 280
    },
    {
        "loss": 0.3285,
        "grad_norm": 9.846802711486816,
        "learning_rate": 1.7827715355805242e-05,
        "epoch": 0.5430711610486891,
        "step": 290
    },
    {
        "loss": 0.3693,
        "grad_norm": 3.6746597290039062,
        "learning_rate": 1.7752808988764045e-05,
        "epoch": 0.5617977528089888,
        "step": 300
    },
    {
        "loss": 0.2922,
        "grad_norm": 20.49506378173828,
        "learning_rate": 1.767790262172285e-05,
        "epoch": 0.5805243445692884,
        "step": 310
    },
    {
        "loss": 0.4114,
        "grad_norm": 17.81382942199707,
        "learning_rate": 1.760299625468165e-05,
        "epoch": 0.599250936329588,
        "step": 320
    },
    {
        "loss": 0.3429,
        "grad_norm": 18.102445602416992,
        "learning_rate": 1.752808988764045e-05,
        "epoch": 0.6179775280898876,
        "step": 330
    },
    {
        "loss": 0.2005,
        "grad_norm": 7.8947062492370605,
        "learning_rate": 1.7453183520599254e-05,
        "epoch": 0.6367041198501873,
        "step": 340
    },
    {
        "loss": 0.3301,
        "grad_norm": 23.772104263305664,
        "learning_rate": 1.7378277153558054e-05,
        "epoch": 0.6554307116104869,
        "step": 350
    },
    {
        "loss": 0.3658,
        "grad_norm": 6.446459770202637,
        "learning_rate": 1.7303370786516857e-05,
        "epoch": 0.6741573033707865,
        "step": 360
    },
    {
        "loss": 0.3667,
        "grad_norm": 9.736032485961914,
        "learning_rate": 1.7228464419475657e-05,
        "epoch": 0.6928838951310862,
        "step": 370
    },
    {
        "loss": 0.3466,
        "grad_norm": 2.3730270862579346,
        "learning_rate": 1.715355805243446e-05,
        "epoch": 0.7116104868913857,
        "step": 380
    },
    {
        "loss": 0.4242,
        "grad_norm": 27.372209548950195,
        "learning_rate": 1.707865168539326e-05,
        "epoch": 0.7303370786516854,
        "step": 390
    },
    {
        "loss": 0.3775,
        "grad_norm": 35.08407211303711,
        "learning_rate": 1.7003745318352062e-05,
        "epoch": 0.7490636704119851,
        "step": 400
    },
    {
        "loss": 0.4261,
        "grad_norm": 14.74215316772461,
        "learning_rate": 1.6928838951310862e-05,
        "epoch": 0.7677902621722846,
        "step": 410
    },
    {
        "loss": 0.3372,
        "grad_norm": 14.041190147399902,
        "learning_rate": 1.6853932584269665e-05,
        "epoch": 0.7865168539325843,
        "step": 420
    },
    {
        "loss": 0.3733,
        "grad_norm": 13.581265449523926,
        "learning_rate": 1.6779026217228468e-05,
        "epoch": 0.8052434456928839,
        "step": 430
    },
    {
        "loss": 0.3377,
        "grad_norm": 13.781243324279785,
        "learning_rate": 1.6704119850187268e-05,
        "epoch": 0.8239700374531835,
        "step": 440
    },
    {
        "loss": 0.3302,
        "grad_norm": 3.4354357719421387,
        "learning_rate": 1.662921348314607e-05,
        "epoch": 0.8426966292134831,
        "step": 450
    },
    {
        "loss": 0.3517,
        "grad_norm": 6.981302261352539,
        "learning_rate": 1.655430711610487e-05,
        "epoch": 0.8614232209737828,
        "step": 460
    },
    {
        "loss": 0.3022,
        "grad_norm": 24.504772186279297,
        "learning_rate": 1.6479400749063673e-05,
        "epoch": 0.8801498127340824,
        "step": 470
    },
    {
        "loss": 0.3308,
        "grad_norm": 8.719352722167969,
        "learning_rate": 1.6404494382022473e-05,
        "epoch": 0.898876404494382,
        "step": 480
    },
    {
        "loss": 0.2547,
        "grad_norm": 7.09309196472168,
        "learning_rate": 1.6329588014981276e-05,
        "epoch": 0.9176029962546817,
        "step": 490
    },
    {
        "loss": 0.3099,
        "grad_norm": 8.690134048461914,
        "learning_rate": 1.6254681647940076e-05,
        "epoch": 0.9363295880149812,
        "step": 500
    },
    {
        "loss": 0.4089,
        "grad_norm": 7.489983558654785,
        "learning_rate": 1.617977528089888e-05,
        "epoch": 0.9550561797752809,
        "step": 510
    },
    {
        "loss": 0.3136,
        "grad_norm": 8.700597763061523,
        "learning_rate": 1.610486891385768e-05,
        "epoch": 0.9737827715355806,
        "step": 520
    },
    {
        "loss": 0.3775,
        "grad_norm": 20.50272560119629,
        "learning_rate": 1.602996254681648e-05,
        "epoch": 0.9925093632958801,
        "step": 530
    },
    {
        "eval_loss": 0.3273351490497589,
        "eval_accuracy": 0.8555347091932458,
        "eval_runtime": 4.2636,
        "eval_samples_per_second": 250.025,
        "eval_steps_per_second": 15.715,
        "epoch": 1.0,
        "step": 534
    },
    {
        "loss": 0.3275,
        "grad_norm": 8.408327102661133,
        "learning_rate": 1.595505617977528e-05,
        "epoch": 1.0112359550561798,
        "step": 540
    },
    {
        "loss": 0.2988,
        "grad_norm": 6.212313652038574,
        "learning_rate": 1.5880149812734084e-05,
        "epoch": 1.0299625468164795,
        "step": 550
    },
    {
        "loss": 0.267,
        "grad_norm": 8.362455368041992,
        "learning_rate": 1.5805243445692887e-05,
        "epoch": 1.048689138576779,
        "step": 560
    },
    {
        "loss": 0.289,
        "grad_norm": 20.461008071899414,
        "learning_rate": 1.5730337078651687e-05,
        "epoch": 1.0674157303370786,
        "step": 570
    },
    {
        "loss": 0.4494,
        "grad_norm": 23.5655460357666,
        "learning_rate": 1.565543071161049e-05,
        "epoch": 1.0861423220973783,
        "step": 580
    },
    {
        "loss": 0.2948,
        "grad_norm": 6.322235107421875,
        "learning_rate": 1.558052434456929e-05,
        "epoch": 1.104868913857678,
        "step": 590
    },
    {
        "loss": 0.1973,
        "grad_norm": 15.723182678222656,
        "learning_rate": 1.5505617977528093e-05,
        "epoch": 1.1235955056179776,
        "step": 600
    },
    {
        "loss": 0.1985,
        "grad_norm": 15.913434982299805,
        "learning_rate": 1.5430711610486892e-05,
        "epoch": 1.142322097378277,
        "step": 610
    },
    {
        "loss": 0.3631,
        "grad_norm": 9.327446937561035,
        "learning_rate": 1.5355805243445695e-05,
        "epoch": 1.1610486891385767,
        "step": 620
    },
    {
        "loss": 0.3594,
        "grad_norm": 19.971555709838867,
        "learning_rate": 1.5280898876404495e-05,
        "epoch": 1.1797752808988764,
        "step": 630
    },
    {
        "loss": 0.2971,
        "grad_norm": 15.006763458251953,
        "learning_rate": 1.5205992509363296e-05,
        "epoch": 1.198501872659176,
        "step": 640
    },
    {
        "loss": 0.2725,
        "grad_norm": 12.246432304382324,
        "learning_rate": 1.5131086142322098e-05,
        "epoch": 1.2172284644194757,
        "step": 650
    },
    {
        "loss": 0.2183,
        "grad_norm": 11.663032531738281,
        "learning_rate": 1.5056179775280899e-05,
        "epoch": 1.2359550561797752,
        "step": 660
    },
    {
        "loss": 0.3192,
        "grad_norm": 16.992307662963867,
        "learning_rate": 1.4981273408239702e-05,
        "epoch": 1.2546816479400749,
        "step": 670
    },
    {
        "loss": 0.3885,
        "grad_norm": 18.762996673583984,
        "learning_rate": 1.4906367041198503e-05,
        "epoch": 1.2734082397003745,
        "step": 680
    },
    {
        "loss": 0.224,
        "grad_norm": 5.22161865234375,
        "learning_rate": 1.4831460674157305e-05,
        "epoch": 1.2921348314606742,
        "step": 690
    },
    {
        "loss": 0.228,
        "grad_norm": 8.79726791381836,
        "learning_rate": 1.4756554307116106e-05,
        "epoch": 1.3108614232209739,
        "step": 700
    },
    {
        "loss": 0.1947,
        "grad_norm": 4.658535480499268,
        "learning_rate": 1.4681647940074907e-05,
        "epoch": 1.3295880149812733,
        "step": 710
    },
    {
        "loss": 0.2068,
        "grad_norm": 10.084193229675293,
        "learning_rate": 1.4606741573033709e-05,
        "epoch": 1.348314606741573,
        "step": 720
    },
    {
        "loss": 0.2783,
        "grad_norm": 9.744063377380371,
        "learning_rate": 1.453183520599251e-05,
        "epoch": 1.3670411985018727,
        "step": 730
    },
    {
        "loss": 0.3548,
        "grad_norm": 20.27412986755371,
        "learning_rate": 1.4456928838951311e-05,
        "epoch": 1.3857677902621723,
        "step": 740
    },
    {
        "loss": 0.3286,
        "grad_norm": 35.176090240478516,
        "learning_rate": 1.4382022471910113e-05,
        "epoch": 1.404494382022472,
        "step": 750
    },
    {
        "loss": 0.1787,
        "grad_norm": 8.55577278137207,
        "learning_rate": 1.4307116104868914e-05,
        "epoch": 1.4232209737827715,
        "step": 760
    },
    {
        "loss": 0.2066,
        "grad_norm": 11.418648719787598,
        "learning_rate": 1.4232209737827715e-05,
        "epoch": 1.4419475655430711,
        "step": 770
    },
    {
        "loss": 0.1738,
        "grad_norm": 14.373414039611816,
        "learning_rate": 1.4157303370786517e-05,
        "epoch": 1.4606741573033708,
        "step": 780
    },
    {
        "loss": 0.2644,
        "grad_norm": 5.400579452514648,
        "learning_rate": 1.408239700374532e-05,
        "epoch": 1.4794007490636705,
        "step": 790
    },
    {
        "loss": 0.3225,
        "grad_norm": 12.645210266113281,
        "learning_rate": 1.4007490636704121e-05,
        "epoch": 1.4981273408239701,
        "step": 800
    },
    {
        "loss": 0.2282,
        "grad_norm": 14.390369415283203,
        "learning_rate": 1.3932584269662923e-05,
        "epoch": 1.5168539325842696,
        "step": 810
    },
    {
        "loss": 0.2797,
        "grad_norm": 15.160231590270996,
        "learning_rate": 1.3857677902621724e-05,
        "epoch": 1.5355805243445693,
        "step": 820
    },
    {
        "loss": 0.2967,
        "grad_norm": 16.545379638671875,
        "learning_rate": 1.3782771535580525e-05,
        "epoch": 1.554307116104869,
        "step": 830
    },
    {
        "loss": 0.2703,
        "grad_norm": 8.851299285888672,
        "learning_rate": 1.3707865168539327e-05,
        "epoch": 1.5730337078651684,
        "step": 840
    },
    {
        "loss": 0.2406,
        "grad_norm": 7.151336669921875,
        "learning_rate": 1.3632958801498128e-05,
        "epoch": 1.5917602996254683,
        "step": 850
    },
    {
        "loss": 0.1872,
        "grad_norm": 30.256996154785156,
        "learning_rate": 1.355805243445693e-05,
        "epoch": 1.6104868913857677,
        "step": 860
    },
    {
        "loss": 0.3474,
        "grad_norm": 6.646709442138672,
        "learning_rate": 1.348314606741573e-05,
        "epoch": 1.6292134831460674,
        "step": 870
    },
    {
        "loss": 0.2618,
        "grad_norm": 4.133448600769043,
        "learning_rate": 1.3408239700374532e-05,
        "epoch": 1.647940074906367,
        "step": 880
    },
    {
        "loss": 0.3186,
        "grad_norm": 11.559736251831055,
        "learning_rate": 1.3333333333333333e-05,
        "epoch": 1.6666666666666665,
        "step": 890
    },
    {
        "loss": 0.2976,
        "grad_norm": 6.587893009185791,
        "learning_rate": 1.3258426966292135e-05,
        "epoch": 1.6853932584269664,
        "step": 900
    },
    {
        "loss": 0.2688,
        "grad_norm": 8.0072660446167,
        "learning_rate": 1.3183520599250936e-05,
        "epoch": 1.7041198501872659,
        "step": 910
    },
    {
        "loss": 0.2891,
        "grad_norm": 16.99168586730957,
        "learning_rate": 1.3108614232209739e-05,
        "epoch": 1.7228464419475655,
        "step": 920
    },
    {
        "loss": 0.2966,
        "grad_norm": 32.70014190673828,
        "learning_rate": 1.303370786516854e-05,
        "epoch": 1.7415730337078652,
        "step": 930
    },
    {
        "loss": 0.3173,
        "grad_norm": 13.445353507995605,
        "learning_rate": 1.2958801498127342e-05,
        "epoch": 1.7602996254681647,
        "step": 940
    },
    {
        "loss": 0.3787,
        "grad_norm": 9.458897590637207,
        "learning_rate": 1.2883895131086143e-05,
        "epoch": 1.7790262172284645,
        "step": 950
    },
    {
        "loss": 0.2989,
        "grad_norm": 10.415778160095215,
        "learning_rate": 1.2808988764044944e-05,
        "epoch": 1.797752808988764,
        "step": 960
    },
    {
        "loss": 0.2523,
        "grad_norm": 38.354949951171875,
        "learning_rate": 1.2734082397003746e-05,
        "epoch": 1.8164794007490637,
        "step": 970
    },
    {
        "loss": 0.2335,
        "grad_norm": 4.32314920425415,
        "learning_rate": 1.2659176029962547e-05,
        "epoch": 1.8352059925093633,
        "step": 980
    },
    {
        "loss": 0.3689,
        "grad_norm": 28.89618682861328,
        "learning_rate": 1.2584269662921348e-05,
        "epoch": 1.8539325842696628,
        "step": 990
    },
    {
        "loss": 0.2468,
        "grad_norm": 4.204697132110596,
        "learning_rate": 1.250936329588015e-05,
        "epoch": 1.8726591760299627,
        "step": 1000
    },
    {
        "loss": 0.2236,
        "grad_norm": 15.451876640319824,
        "learning_rate": 1.2434456928838951e-05,
        "epoch": 1.8913857677902621,
        "step": 1010
    },
    {
        "loss": 0.4492,
        "grad_norm": 20.8867130279541,
        "learning_rate": 1.2359550561797752e-05,
        "epoch": 1.9101123595505618,
        "step": 1020
    },
    {
        "loss": 0.2157,
        "grad_norm": 18.25041961669922,
        "learning_rate": 1.2284644194756554e-05,
        "epoch": 1.9288389513108615,
        "step": 1030
    },
    {
        "loss": 0.384,
        "grad_norm": 15.279638290405273,
        "learning_rate": 1.2209737827715359e-05,
        "epoch": 1.947565543071161,
        "step": 1040
    },
    {
        "loss": 0.1799,
        "grad_norm": 27.547401428222656,
        "learning_rate": 1.213483146067416e-05,
        "epoch": 1.9662921348314608,
        "step": 1050
    },
    {
        "loss": 0.2216,
        "grad_norm": 2.1905109882354736,
        "learning_rate": 1.205992509363296e-05,
        "epoch": 1.9850187265917603,
        "step": 1060
    },
    {
        "eval_loss": 0.34144023060798645,
        "eval_accuracy": 0.8893058161350844,
        "eval_runtime": 4.1795,
        "eval_samples_per_second": 255.054,
        "eval_steps_per_second": 16.031,
        "epoch": 2.0,
        "step": 1068
    },
    {
        "loss": 0.2192,
        "grad_norm": 10.4259033203125,
        "learning_rate": 1.1985018726591761e-05,
        "epoch": 2.0037453183520597,
        "step": 1070
    },
    {
        "loss": 0.1784,
        "grad_norm": 22.743284225463867,
        "learning_rate": 1.1910112359550562e-05,
        "epoch": 2.0224719101123596,
        "step": 1080
    },
    {
        "loss": 0.2218,
        "grad_norm": 16.368410110473633,
        "learning_rate": 1.1835205992509364e-05,
        "epoch": 2.041198501872659,
        "step": 1090
    },
    {
        "loss": 0.2739,
        "grad_norm": 42.893436431884766,
        "learning_rate": 1.1760299625468165e-05,
        "epoch": 2.059925093632959,
        "step": 1100
    },
    {
        "loss": 0.3189,
        "grad_norm": 21.23488998413086,
        "learning_rate": 1.1685393258426966e-05,
        "epoch": 2.0786516853932584,
        "step": 1110
    },
    {
        "loss": 0.1978,
        "grad_norm": 12.955072402954102,
        "learning_rate": 1.1610486891385768e-05,
        "epoch": 2.097378277153558,
        "step": 1120
    },
    {
        "loss": 0.1863,
        "grad_norm": 0.9682953953742981,
        "learning_rate": 1.1535580524344569e-05,
        "epoch": 2.1161048689138577,
        "step": 1130
    },
    {
        "loss": 0.2362,
        "grad_norm": 12.719749450683594,
        "learning_rate": 1.146067415730337e-05,
        "epoch": 2.134831460674157,
        "step": 1140
    },
    {
        "loss": 0.1824,
        "grad_norm": 21.42571449279785,
        "learning_rate": 1.1385767790262172e-05,
        "epoch": 2.153558052434457,
        "step": 1150
    },
    {
        "loss": 0.1621,
        "grad_norm": 20.129961013793945,
        "learning_rate": 1.1310861423220976e-05,
        "epoch": 2.1722846441947565,
        "step": 1160
    },
    {
        "loss": 0.2706,
        "grad_norm": 89.86812591552734,
        "learning_rate": 1.1235955056179778e-05,
        "epoch": 2.191011235955056,
        "step": 1170
    },
    {
        "loss": 0.2385,
        "grad_norm": 3.972506046295166,
        "learning_rate": 1.1161048689138579e-05,
        "epoch": 2.209737827715356,
        "step": 1180
    },
    {
        "loss": 0.1923,
        "grad_norm": 14.24902057647705,
        "learning_rate": 1.108614232209738e-05,
        "epoch": 2.2284644194756553,
        "step": 1190
    },
    {
        "loss": 0.3045,
        "grad_norm": 2.1389801502227783,
        "learning_rate": 1.101123595505618e-05,
        "epoch": 2.247191011235955,
        "step": 1200
    },
    {
        "loss": 0.2362,
        "grad_norm": 17.51442527770996,
        "learning_rate": 1.0936329588014981e-05,
        "epoch": 2.2659176029962547,
        "step": 1210
    },
    {
        "loss": 0.1817,
        "grad_norm": 0.41732341051101685,
        "learning_rate": 1.0861423220973783e-05,
        "epoch": 2.284644194756554,
        "step": 1220
    },
    {
        "loss": 0.2468,
        "grad_norm": 7.034875869750977,
        "learning_rate": 1.0786516853932584e-05,
        "epoch": 2.303370786516854,
        "step": 1230
    },
    {
        "loss": 0.1312,
        "grad_norm": 7.39605188369751,
        "learning_rate": 1.0711610486891385e-05,
        "epoch": 2.3220973782771535,
        "step": 1240
    },
    {
        "loss": 0.2924,
        "grad_norm": 28.127933502197266,
        "learning_rate": 1.0636704119850187e-05,
        "epoch": 2.3408239700374533,
        "step": 1250
    },
    {
        "loss": 0.1973,
        "grad_norm": 13.670125007629395,
        "learning_rate": 1.0561797752808988e-05,
        "epoch": 2.359550561797753,
        "step": 1260
    },
    {
        "loss": 0.2208,
        "grad_norm": 25.747350692749023,
        "learning_rate": 1.048689138576779e-05,
        "epoch": 2.3782771535580522,
        "step": 1270
    },
    {
        "loss": 0.2184,
        "grad_norm": 32.27301025390625,
        "learning_rate": 1.0411985018726594e-05,
        "epoch": 2.397003745318352,
        "step": 1280
    },
    {
        "loss": 0.1988,
        "grad_norm": 14.002302169799805,
        "learning_rate": 1.0337078651685396e-05,
        "epoch": 2.4157303370786516,
        "step": 1290
    },
    {
        "loss": 0.1485,
        "grad_norm": 7.606315612792969,
        "learning_rate": 1.0262172284644197e-05,
        "epoch": 2.4344569288389515,
        "step": 1300
    },
    {
        "loss": 0.1795,
        "grad_norm": 15.162211418151855,
        "learning_rate": 1.0187265917602998e-05,
        "epoch": 2.453183520599251,
        "step": 1310
    },
    {
        "loss": 0.1917,
        "grad_norm": 9.229268074035645,
        "learning_rate": 1.01123595505618e-05,
        "epoch": 2.4719101123595504,
        "step": 1320
    },
    {
        "loss": 0.2384,
        "grad_norm": 39.02178192138672,
        "learning_rate": 1.0037453183520601e-05,
        "epoch": 2.4906367041198503,
        "step": 1330
    },
    {
        "loss": 0.3065,
        "grad_norm": 17.66401481628418,
        "learning_rate": 9.9625468164794e-06,
        "epoch": 2.5093632958801497,
        "step": 1340
    },
    {
        "loss": 0.2369,
        "grad_norm": 18.89865493774414,
        "learning_rate": 9.887640449438202e-06,
        "epoch": 2.5280898876404496,
        "step": 1350
    },
    {
        "loss": 0.2203,
        "grad_norm": 24.79997444152832,
        "learning_rate": 9.812734082397003e-06,
        "epoch": 2.546816479400749,
        "step": 1360
    },
    {
        "loss": 0.1867,
        "grad_norm": 18.236600875854492,
        "learning_rate": 9.737827715355806e-06,
        "epoch": 2.5655430711610485,
        "step": 1370
    },
    {
        "loss": 0.1513,
        "grad_norm": 16.015439987182617,
        "learning_rate": 9.662921348314608e-06,
        "epoch": 2.5842696629213484,
        "step": 1380
    },
    {
        "loss": 0.2228,
        "grad_norm": 6.02846622467041,
        "learning_rate": 9.588014981273409e-06,
        "epoch": 2.602996254681648,
        "step": 1390
    },
    {
        "loss": 0.1879,
        "grad_norm": 12.323101043701172,
        "learning_rate": 9.51310861423221e-06,
        "epoch": 2.6217228464419478,
        "step": 1400
    },
    {
        "loss": 0.1789,
        "grad_norm": 17.572729110717773,
        "learning_rate": 9.438202247191012e-06,
        "epoch": 2.640449438202247,
        "step": 1410
    },
    {
        "loss": 0.234,
        "grad_norm": 14.960287094116211,
        "learning_rate": 9.363295880149813e-06,
        "epoch": 2.6591760299625467,
        "step": 1420
    },
    {
        "loss": 0.1693,
        "grad_norm": 6.743465423583984,
        "learning_rate": 9.288389513108616e-06,
        "epoch": 2.6779026217228465,
        "step": 1430
    },
    {
        "loss": 0.3138,
        "grad_norm": 24.174518585205078,
        "learning_rate": 9.213483146067417e-06,
        "epoch": 2.696629213483146,
        "step": 1440
    },
    {
        "loss": 0.2295,
        "grad_norm": 2.4781200885772705,
        "learning_rate": 9.138576779026219e-06,
        "epoch": 2.715355805243446,
        "step": 1450
    },
    {
        "loss": 0.23,
        "grad_norm": 8.13705062866211,
        "learning_rate": 9.06367041198502e-06,
        "epoch": 2.7340823970037453,
        "step": 1460
    },
    {
        "loss": 0.2031,
        "grad_norm": 21.952146530151367,
        "learning_rate": 8.988764044943822e-06,
        "epoch": 2.752808988764045,
        "step": 1470
    },
    {
        "loss": 0.182,
        "grad_norm": 2.858654737472534,
        "learning_rate": 8.913857677902621e-06,
        "epoch": 2.7715355805243447,
        "step": 1480
    },
    {
        "loss": 0.3052,
        "grad_norm": 3.8055989742279053,
        "learning_rate": 8.838951310861424e-06,
        "epoch": 2.790262172284644,
        "step": 1490
    },
    {
        "loss": 0.3827,
        "grad_norm": 30.499576568603516,
        "learning_rate": 8.764044943820226e-06,
        "epoch": 2.808988764044944,
        "step": 1500
    },
    {
        "loss": 0.1176,
        "grad_norm": 7.90937614440918,
        "learning_rate": 8.689138576779027e-06,
        "epoch": 2.8277153558052435,
        "step": 1510
    },
    {
        "loss": 0.1387,
        "grad_norm": 35.93660354614258,
        "learning_rate": 8.614232209737828e-06,
        "epoch": 2.846441947565543,
        "step": 1520
    },
    {
        "loss": 0.2867,
        "grad_norm": 9.528658866882324,
        "learning_rate": 8.53932584269663e-06,
        "epoch": 2.865168539325843,
        "step": 1530
    },
    {
        "loss": 0.2439,
        "grad_norm": 13.803389549255371,
        "learning_rate": 8.464419475655431e-06,
        "epoch": 2.8838951310861423,
        "step": 1540
    },
    {
        "loss": 0.2228,
        "grad_norm": 12.021435737609863,
        "learning_rate": 8.389513108614234e-06,
        "epoch": 2.902621722846442,
        "step": 1550
    },
    {
        "loss": 0.3079,
        "grad_norm": 28.737743377685547,
        "learning_rate": 8.314606741573035e-06,
        "epoch": 2.9213483146067416,
        "step": 1560
    },
    {
        "loss": 0.1923,
        "grad_norm": 14.27962589263916,
        "learning_rate": 8.239700374531837e-06,
        "epoch": 2.940074906367041,
        "step": 1570
    },
    {
        "loss": 0.1519,
        "grad_norm": 34.975929260253906,
        "learning_rate": 8.164794007490638e-06,
        "epoch": 2.958801498127341,
        "step": 1580
    },
    {
        "loss": 0.2011,
        "grad_norm": 0.5970475077629089,
        "learning_rate": 8.08988764044944e-06,
        "epoch": 2.9775280898876404,
        "step": 1590
    },
    {
        "loss": 0.2297,
        "grad_norm": 52.79434585571289,
        "learning_rate": 8.01498127340824e-06,
        "epoch": 2.9962546816479403,
        "step": 1600
    },
    {
        "eval_loss": 0.31462791562080383,
        "eval_accuracy": 0.8939962476547842,
        "eval_runtime": 4.2457,
        "eval_samples_per_second": 251.076,
        "eval_steps_per_second": 15.781,
        "epoch": 3.0,
        "step": 1602
    },
    {
        "loss": 0.139,
        "grad_norm": 12.962203979492188,
        "learning_rate": 7.940074906367042e-06,
        "epoch": 3.0149812734082397,
        "step": 1610
    },
    {
        "loss": 0.1651,
        "grad_norm": 40.044925689697266,
        "learning_rate": 7.865168539325843e-06,
        "epoch": 3.033707865168539,
        "step": 1620
    },
    {
        "loss": 0.1662,
        "grad_norm": 19.5877628326416,
        "learning_rate": 7.790262172284645e-06,
        "epoch": 3.052434456928839,
        "step": 1630
    },
    {
        "loss": 0.0833,
        "grad_norm": 1.3629345893859863,
        "learning_rate": 7.715355805243446e-06,
        "epoch": 3.0711610486891385,
        "step": 1640
    },
    {
        "loss": 0.1638,
        "grad_norm": 21.952470779418945,
        "learning_rate": 7.640449438202247e-06,
        "epoch": 3.0898876404494384,
        "step": 1650
    },
    {
        "loss": 0.1367,
        "grad_norm": 17.098230361938477,
        "learning_rate": 7.565543071161049e-06,
        "epoch": 3.108614232209738,
        "step": 1660
    },
    {
        "loss": 0.1409,
        "grad_norm": 14.452770233154297,
        "learning_rate": 7.490636704119851e-06,
        "epoch": 3.1273408239700373,
        "step": 1670
    },
    {
        "loss": 0.2258,
        "grad_norm": 9.152499198913574,
        "learning_rate": 7.415730337078652e-06,
        "epoch": 3.146067415730337,
        "step": 1680
    },
    {
        "loss": 0.1332,
        "grad_norm": 28.641965866088867,
        "learning_rate": 7.340823970037454e-06,
        "epoch": 3.1647940074906367,
        "step": 1690
    },
    {
        "loss": 0.208,
        "grad_norm": 4.044565677642822,
        "learning_rate": 7.265917602996255e-06,
        "epoch": 3.1835205992509366,
        "step": 1700
    },
    {
        "loss": 0.2462,
        "grad_norm": 25.34758949279785,
        "learning_rate": 7.191011235955056e-06,
        "epoch": 3.202247191011236,
        "step": 1710
    },
    {
        "loss": 0.192,
        "grad_norm": 24.662986755371094,
        "learning_rate": 7.116104868913858e-06,
        "epoch": 3.2209737827715355,
        "step": 1720
    },
    {
        "loss": 0.2551,
        "grad_norm": 11.667508125305176,
        "learning_rate": 7.04119850187266e-06,
        "epoch": 3.2397003745318353,
        "step": 1730
    },
    {
        "loss": 0.1535,
        "grad_norm": 23.621747970581055,
        "learning_rate": 6.966292134831461e-06,
        "epoch": 3.258426966292135,
        "step": 1740
    },
    {
        "loss": 0.0748,
        "grad_norm": 3.5678157806396484,
        "learning_rate": 6.891385767790263e-06,
        "epoch": 3.2771535580524347,
        "step": 1750
    },
    {
        "loss": 0.1361,
        "grad_norm": 3.1957101821899414,
        "learning_rate": 6.816479400749064e-06,
        "epoch": 3.295880149812734,
        "step": 1760
    },
    {
        "loss": 0.1587,
        "grad_norm": 7.832240104675293,
        "learning_rate": 6.741573033707865e-06,
        "epoch": 3.3146067415730336,
        "step": 1770
    },
    {
        "loss": 0.3042,
        "grad_norm": 16.987455368041992,
        "learning_rate": 6.666666666666667e-06,
        "epoch": 3.3333333333333335,
        "step": 1780
    },
    {
        "loss": 0.0747,
        "grad_norm": 24.858312606811523,
        "learning_rate": 6.591760299625468e-06,
        "epoch": 3.352059925093633,
        "step": 1790
    },
    {
        "loss": 0.1831,
        "grad_norm": 42.66535949707031,
        "learning_rate": 6.51685393258427e-06,
        "epoch": 3.370786516853933,
        "step": 1800
    },
    {
        "loss": 0.1302,
        "grad_norm": 11.345052719116211,
        "learning_rate": 6.4419475655430715e-06,
        "epoch": 3.3895131086142323,
        "step": 1810
    },
    {
        "loss": 0.1339,
        "grad_norm": 3.6963818073272705,
        "learning_rate": 6.367041198501873e-06,
        "epoch": 3.4082397003745317,
        "step": 1820
    },
    {
        "loss": 0.2091,
        "grad_norm": 32.83697509765625,
        "learning_rate": 6.292134831460674e-06,
        "epoch": 3.4269662921348316,
        "step": 1830
    },
    {
        "loss": 0.1716,
        "grad_norm": 19.66389274597168,
        "learning_rate": 6.2172284644194756e-06,
        "epoch": 3.445692883895131,
        "step": 1840
    },
    {
        "loss": 0.1728,
        "grad_norm": 0.8683643937110901,
        "learning_rate": 6.142322097378277e-06,
        "epoch": 3.464419475655431,
        "step": 1850
    },
    {
        "loss": 0.2722,
        "grad_norm": 0.30638188123703003,
        "learning_rate": 6.06741573033708e-06,
        "epoch": 3.4831460674157304,
        "step": 1860
    },
    {
        "loss": 0.17,
        "grad_norm": 12.164915084838867,
        "learning_rate": 5.9925093632958805e-06,
        "epoch": 3.50187265917603,
        "step": 1870
    },
    {
        "loss": 0.1231,
        "grad_norm": 0.9181548357009888,
        "learning_rate": 5.917602996254682e-06,
        "epoch": 3.5205992509363297,
        "step": 1880
    },
    {
        "loss": 0.1891,
        "grad_norm": 6.825005531311035,
        "learning_rate": 5.842696629213483e-06,
        "epoch": 3.539325842696629,
        "step": 1890
    },
    {
        "loss": 0.1189,
        "grad_norm": 11.349286079406738,
        "learning_rate": 5.7677902621722845e-06,
        "epoch": 3.558052434456929,
        "step": 1900
    },
    {
        "loss": 0.1102,
        "grad_norm": 20.523576736450195,
        "learning_rate": 5.692883895131086e-06,
        "epoch": 3.5767790262172285,
        "step": 1910
    },
    {
        "loss": 0.2569,
        "grad_norm": 79.2723617553711,
        "learning_rate": 5.617977528089889e-06,
        "epoch": 3.595505617977528,
        "step": 1920
    },
    {
        "loss": 0.24,
        "grad_norm": 18.36128807067871,
        "learning_rate": 5.54307116104869e-06,
        "epoch": 3.6142322097378274,
        "step": 1930
    },
    {
        "loss": 0.1903,
        "grad_norm": 4.959616661071777,
        "learning_rate": 5.468164794007491e-06,
        "epoch": 3.6329588014981273,
        "step": 1940
    },
    {
        "loss": 0.2409,
        "grad_norm": 36.818077087402344,
        "learning_rate": 5.393258426966292e-06,
        "epoch": 3.6516853932584272,
        "step": 1950
    },
    {
        "loss": 0.2126,
        "grad_norm": 9.474709510803223,
        "learning_rate": 5.318352059925093e-06,
        "epoch": 3.6704119850187267,
        "step": 1960
    },
    {
        "loss": 0.1634,
        "grad_norm": 1.113046407699585,
        "learning_rate": 5.243445692883895e-06,
        "epoch": 3.689138576779026,
        "step": 1970
    },
    {
        "loss": 0.228,
        "grad_norm": 21.002485275268555,
        "learning_rate": 5.168539325842698e-06,
        "epoch": 3.7078651685393256,
        "step": 1980
    },
    {
        "loss": 0.1767,
        "grad_norm": 42.64962387084961,
        "learning_rate": 5.093632958801499e-06,
        "epoch": 3.7265917602996255,
        "step": 1990
    },
    {
        "loss": 0.2613,
        "grad_norm": 9.889809608459473,
        "learning_rate": 5.0187265917603005e-06,
        "epoch": 3.7453183520599254,
        "step": 2000
    },
    {
        "loss": 0.2119,
        "grad_norm": 15.239461898803711,
        "learning_rate": 4.943820224719101e-06,
        "epoch": 3.764044943820225,
        "step": 2010
    },
    {
        "loss": 0.1388,
        "grad_norm": 2.245645523071289,
        "learning_rate": 4.868913857677903e-06,
        "epoch": 3.7827715355805243,
        "step": 2020
    },
    {
        "loss": 0.2247,
        "grad_norm": 19.908790588378906,
        "learning_rate": 4.7940074906367045e-06,
        "epoch": 3.8014981273408237,
        "step": 2030
    },
    {
        "loss": 0.113,
        "grad_norm": 22.162702560424805,
        "learning_rate": 4.719101123595506e-06,
        "epoch": 3.8202247191011236,
        "step": 2040
    },
    {
        "loss": 0.3263,
        "grad_norm": 21.271350860595703,
        "learning_rate": 4.644194756554308e-06,
        "epoch": 3.8389513108614235,
        "step": 2050
    },
    {
        "loss": 0.088,
        "grad_norm": 18.676034927368164,
        "learning_rate": 4.569288389513109e-06,
        "epoch": 3.857677902621723,
        "step": 2060
    },
    {
        "loss": 0.2137,
        "grad_norm": 13.810401916503906,
        "learning_rate": 4.494382022471911e-06,
        "epoch": 3.8764044943820224,
        "step": 2070
    },
    {
        "loss": 0.1784,
        "grad_norm": 2.196153402328491,
        "learning_rate": 4.419475655430712e-06,
        "epoch": 3.895131086142322,
        "step": 2080
    },
    {
        "loss": 0.1743,
        "grad_norm": 29.77124786376953,
        "learning_rate": 4.3445692883895135e-06,
        "epoch": 3.9138576779026217,
        "step": 2090
    },
    {
        "loss": 0.1713,
        "grad_norm": 11.073521614074707,
        "learning_rate": 4.269662921348315e-06,
        "epoch": 3.932584269662921,
        "step": 2100
    },
    {
        "loss": 0.1042,
        "grad_norm": 15.968642234802246,
        "learning_rate": 4.194756554307117e-06,
        "epoch": 3.951310861423221,
        "step": 2110
    },
    {
        "loss": 0.1305,
        "grad_norm": 18.69753646850586,
        "learning_rate": 4.119850187265918e-06,
        "epoch": 3.9700374531835205,
        "step": 2120
    },
    {
        "loss": 0.0955,
        "grad_norm": 46.17475509643555,
        "learning_rate": 4.04494382022472e-06,
        "epoch": 3.98876404494382,
        "step": 2130
    },
    {
        "eval_loss": 0.3693873882293701,
        "eval_accuracy": 0.8958724202626641,
        "eval_runtime": 4.2399,
        "eval_samples_per_second": 251.422,
        "eval_steps_per_second": 15.802,
        "epoch": 4.0,
        "step": 2136
    },
    {
        "loss": 0.0656,
        "grad_norm": 4.505726337432861,
        "learning_rate": 3.970037453183521e-06,
        "epoch": 4.007490636704119,
        "step": 2140
    },
    {
        "loss": 0.2072,
        "grad_norm": 36.31583786010742,
        "learning_rate": 3.895131086142322e-06,
        "epoch": 4.02621722846442,
        "step": 2150
    },
    {
        "loss": 0.1077,
        "grad_norm": 43.794734954833984,
        "learning_rate": 3.820224719101124e-06,
        "epoch": 4.044943820224719,
        "step": 2160
    },
    {
        "loss": 0.2705,
        "grad_norm": 30.00943946838379,
        "learning_rate": 3.7453183520599255e-06,
        "epoch": 4.063670411985019,
        "step": 2170
    },
    {
        "loss": 0.0795,
        "grad_norm": 65.06519317626953,
        "learning_rate": 3.670411985018727e-06,
        "epoch": 4.082397003745318,
        "step": 2180
    },
    {
        "loss": 0.13,
        "grad_norm": 7.191352367401123,
        "learning_rate": 3.595505617977528e-06,
        "epoch": 4.101123595505618,
        "step": 2190
    },
    {
        "loss": 0.2058,
        "grad_norm": 9.841503143310547,
        "learning_rate": 3.52059925093633e-06,
        "epoch": 4.119850187265918,
        "step": 2200
    },
    {
        "loss": 0.0789,
        "grad_norm": 1.3676611185073853,
        "learning_rate": 3.4456928838951313e-06,
        "epoch": 4.138576779026217,
        "step": 2210
    },
    {
        "loss": 0.0756,
        "grad_norm": 12.346567153930664,
        "learning_rate": 3.3707865168539327e-06,
        "epoch": 4.157303370786517,
        "step": 2220
    },
    {
        "loss": 0.241,
        "grad_norm": 27.620872497558594,
        "learning_rate": 3.295880149812734e-06,
        "epoch": 4.176029962546816,
        "step": 2230
    },
    {
        "loss": 0.1516,
        "grad_norm": 46.56419372558594,
        "learning_rate": 3.2209737827715358e-06,
        "epoch": 4.194756554307116,
        "step": 2240
    },
    {
        "loss": 0.0822,
        "grad_norm": 12.549449920654297,
        "learning_rate": 3.146067415730337e-06,
        "epoch": 4.213483146067416,
        "step": 2250
    },
    {
        "loss": 0.0995,
        "grad_norm": 1.111518383026123,
        "learning_rate": 3.0711610486891385e-06,
        "epoch": 4.2322097378277155,
        "step": 2260
    },
    {
        "loss": 0.1275,
        "grad_norm": 32.89590835571289,
        "learning_rate": 2.9962546816479402e-06,
        "epoch": 4.250936329588015,
        "step": 2270
    },
    {
        "loss": 0.1852,
        "grad_norm": 22.833351135253906,
        "learning_rate": 2.9213483146067416e-06,
        "epoch": 4.269662921348314,
        "step": 2280
    },
    {
        "loss": 0.0518,
        "grad_norm": 0.26857930421829224,
        "learning_rate": 2.846441947565543e-06,
        "epoch": 4.288389513108614,
        "step": 2290
    },
    {
        "loss": 0.0501,
        "grad_norm": 27.11154556274414,
        "learning_rate": 2.771535580524345e-06,
        "epoch": 4.307116104868914,
        "step": 2300
    },
    {
        "loss": 0.1629,
        "grad_norm": 1.0618339776992798,
        "learning_rate": 2.696629213483146e-06,
        "epoch": 4.325842696629214,
        "step": 2310
    },
    {
        "loss": 0.2678,
        "grad_norm": 50.25679397583008,
        "learning_rate": 2.6217228464419474e-06,
        "epoch": 4.344569288389513,
        "step": 2320
    },
    {
        "loss": 0.1257,
        "grad_norm": 0.28058940172195435,
        "learning_rate": 2.5468164794007496e-06,
        "epoch": 4.3632958801498125,
        "step": 2330
    },
    {
        "loss": 0.1979,
        "grad_norm": 57.15748977661133,
        "learning_rate": 2.4719101123595505e-06,
        "epoch": 4.382022471910112,
        "step": 2340
    },
    {
        "loss": 0.1009,
        "grad_norm": 46.735931396484375,
        "learning_rate": 2.3970037453183523e-06,
        "epoch": 4.400749063670412,
        "step": 2350
    },
    {
        "loss": 0.1077,
        "grad_norm": 11.300132751464844,
        "learning_rate": 2.322097378277154e-06,
        "epoch": 4.419475655430712,
        "step": 2360
    },
    {
        "loss": 0.1633,
        "grad_norm": 15.639900207519531,
        "learning_rate": 2.2471910112359554e-06,
        "epoch": 4.438202247191011,
        "step": 2370
    },
    {
        "loss": 0.1188,
        "grad_norm": 64.3870620727539,
        "learning_rate": 2.1722846441947567e-06,
        "epoch": 4.456928838951311,
        "step": 2380
    },
    {
        "loss": 0.1456,
        "grad_norm": 46.347721099853516,
        "learning_rate": 2.0973782771535585e-06,
        "epoch": 4.47565543071161,
        "step": 2390
    },
    {
        "loss": 0.1686,
        "grad_norm": 0.41717860102653503,
        "learning_rate": 2.02247191011236e-06,
        "epoch": 4.49438202247191,
        "step": 2400
    },
    {
        "loss": 0.2341,
        "grad_norm": 25.68599510192871,
        "learning_rate": 1.947565543071161e-06,
        "epoch": 4.51310861423221,
        "step": 2410
    },
    {
        "loss": 0.0986,
        "grad_norm": 5.617011070251465,
        "learning_rate": 1.8726591760299627e-06,
        "epoch": 4.531835205992509,
        "step": 2420
    },
    {
        "loss": 0.129,
        "grad_norm": 7.328174114227295,
        "learning_rate": 1.797752808988764e-06,
        "epoch": 4.550561797752809,
        "step": 2430
    },
    {
        "loss": 0.1325,
        "grad_norm": 41.59525680541992,
        "learning_rate": 1.7228464419475657e-06,
        "epoch": 4.569288389513108,
        "step": 2440
    },
    {
        "loss": 0.1693,
        "grad_norm": 5.2094621658325195,
        "learning_rate": 1.647940074906367e-06,
        "epoch": 4.588014981273409,
        "step": 2450
    },
    {
        "loss": 0.2192,
        "grad_norm": 31.598342895507812,
        "learning_rate": 1.5730337078651686e-06,
        "epoch": 4.606741573033708,
        "step": 2460
    },
    {
        "loss": 0.158,
        "grad_norm": 35.962825775146484,
        "learning_rate": 1.4981273408239701e-06,
        "epoch": 4.6254681647940075,
        "step": 2470
    },
    {
        "loss": 0.2151,
        "grad_norm": 16.280258178710938,
        "learning_rate": 1.4232209737827715e-06,
        "epoch": 4.644194756554307,
        "step": 2480
    },
    {
        "loss": 0.0453,
        "grad_norm": 0.5520108938217163,
        "learning_rate": 1.348314606741573e-06,
        "epoch": 4.662921348314606,
        "step": 2490
    },
    {
        "loss": 0.1882,
        "grad_norm": 27.78293800354004,
        "learning_rate": 1.2734082397003748e-06,
        "epoch": 4.681647940074907,
        "step": 2500
    },
    {
        "loss": 0.1543,
        "grad_norm": 56.610042572021484,
        "learning_rate": 1.1985018726591761e-06,
        "epoch": 4.700374531835206,
        "step": 2510
    },
    {
        "loss": 0.1262,
        "grad_norm": 0.2625911831855774,
        "learning_rate": 1.1235955056179777e-06,
        "epoch": 4.719101123595506,
        "step": 2520
    },
    {
        "loss": 0.1067,
        "grad_norm": 0.5069036483764648,
        "learning_rate": 1.0486891385767792e-06,
        "epoch": 4.737827715355805,
        "step": 2530
    },
    {
        "loss": 0.1075,
        "grad_norm": 0.6847344040870667,
        "learning_rate": 9.737827715355806e-07,
        "epoch": 4.7565543071161045,
        "step": 2540
    },
    {
        "loss": 0.1407,
        "grad_norm": 0.277927041053772,
        "learning_rate": 8.98876404494382e-07,
        "epoch": 4.775280898876405,
        "step": 2550
    },
    {
        "loss": 0.1465,
        "grad_norm": 34.91453552246094,
        "learning_rate": 8.239700374531835e-07,
        "epoch": 4.794007490636704,
        "step": 2560
    },
    {
        "loss": 0.1734,
        "grad_norm": 0.4936007261276245,
        "learning_rate": 7.490636704119851e-07,
        "epoch": 4.812734082397004,
        "step": 2570
    },
    {
        "loss": 0.0424,
        "grad_norm": 4.373391151428223,
        "learning_rate": 6.741573033707865e-07,
        "epoch": 4.831460674157303,
        "step": 2580
    },
    {
        "loss": 0.1194,
        "grad_norm": 2.0996205806732178,
        "learning_rate": 5.992509363295881e-07,
        "epoch": 4.850187265917603,
        "step": 2590
    },
    {
        "loss": 0.1996,
        "grad_norm": 51.463706970214844,
        "learning_rate": 5.243445692883896e-07,
        "epoch": 4.868913857677903,
        "step": 2600
    },
    {
        "loss": 0.2933,
        "grad_norm": 0.16638658940792084,
        "learning_rate": 4.49438202247191e-07,
        "epoch": 4.887640449438202,
        "step": 2610
    },
    {
        "loss": 0.1528,
        "grad_norm": 0.13556239008903503,
        "learning_rate": 3.7453183520599253e-07,
        "epoch": 4.906367041198502,
        "step": 2620
    },
    {
        "loss": 0.0724,
        "grad_norm": 72.01959991455078,
        "learning_rate": 2.9962546816479403e-07,
        "epoch": 4.925093632958801,
        "step": 2630
    },
    {
        "loss": 0.112,
        "grad_norm": 9.435591697692871,
        "learning_rate": 2.247191011235955e-07,
        "epoch": 4.943820224719101,
        "step": 2640
    },
    {
        "loss": 0.1513,
        "grad_norm": 19.51644515991211,
        "learning_rate": 1.4981273408239702e-07,
        "epoch": 4.962546816479401,
        "step": 2650
    },
    {
        "loss": 0.09,
        "grad_norm": 16.391769409179688,
        "learning_rate": 7.490636704119851e-08,
        "epoch": 4.9812734082397006,
        "step": 2660
    },
    {
        "loss": 0.2423,
        "grad_norm": 230.7976531982422,
        "learning_rate": 0.0,
        "epoch": 5.0,
        "step": 2670
    },
    {
        "eval_loss": 0.4422072768211365,
        "eval_accuracy": 0.8986866791744841,
        "eval_runtime": 4.6415,
        "eval_samples_per_second": 229.669,
        "eval_steps_per_second": 14.435,
        "epoch": 5.0,
        "step": 2670
    },
    {
        "train_runtime": 591.5468,
        "train_samples_per_second": 72.099,
        "train_steps_per_second": 4.514,
        "total_flos": 1718852108011320.0,
        "train_loss": 0.24361743457085183,
        "epoch": 5.0,
        "step": 2670
    },
    {
        "eval_loss": 0.5741530656814575,
        "eval_accuracy": 0.875234521575985,
        "eval_runtime": 4.0491,
        "eval_samples_per_second": 263.267,
        "eval_steps_per_second": 16.547,
        "epoch": 5.0,
        "step": 2670
    }
]