[
    {
        "loss": 0.7295,
        "grad_norm": 6.51271915435791,
        "learning_rate": 1.99250936329588e-05,
        "epoch": 0.018726591760299626,
        "step": 10
    },
    {
        "loss": 0.6444,
        "grad_norm": 11.250041961669922,
        "learning_rate": 1.9850187265917604e-05,
        "epoch": 0.03745318352059925,
        "step": 20
    },
    {
        "loss": 0.6459,
        "grad_norm": 6.7767653465271,
        "learning_rate": 1.9775280898876404e-05,
        "epoch": 0.056179775280898875,
        "step": 30
    },
    {
        "loss": 0.747,
        "grad_norm": 12.829572677612305,
        "learning_rate": 1.9700374531835207e-05,
        "epoch": 0.0749063670411985,
        "step": 40
    },
    {
        "loss": 0.7005,
        "grad_norm": 12.835592269897461,
        "learning_rate": 1.9625468164794007e-05,
        "epoch": 0.09363295880149813,
        "step": 50
    },
    {
        "loss": 0.7081,
        "grad_norm": 7.438335418701172,
        "learning_rate": 1.955056179775281e-05,
        "epoch": 0.11235955056179775,
        "step": 60
    },
    {
        "loss": 0.5707,
        "grad_norm": 10.074670791625977,
        "learning_rate": 1.9475655430711613e-05,
        "epoch": 0.13108614232209737,
        "step": 70
    },
    {
        "loss": 0.6156,
        "grad_norm": 10.935644149780273,
        "learning_rate": 1.9400749063670416e-05,
        "epoch": 0.149812734082397,
        "step": 80
    },
    {
        "loss": 0.6023,
        "grad_norm": 6.790561199188232,
        "learning_rate": 1.9325842696629215e-05,
        "epoch": 0.16853932584269662,
        "step": 90
    },
    {
        "loss": 0.6134,
        "grad_norm": 16.158363342285156,
        "learning_rate": 1.925093632958802e-05,
        "epoch": 0.18726591760299627,
        "step": 100
    },
    {
        "loss": 0.4519,
        "grad_norm": 9.005303382873535,
        "learning_rate": 1.9176029962546818e-05,
        "epoch": 0.20599250936329588,
        "step": 110
    },
    {
        "loss": 0.5818,
        "grad_norm": 12.675461769104004,
        "learning_rate": 1.910112359550562e-05,
        "epoch": 0.2247191011235955,
        "step": 120
    },
    {
        "loss": 0.5428,
        "grad_norm": 5.673503875732422,
        "learning_rate": 1.902621722846442e-05,
        "epoch": 0.24344569288389514,
        "step": 130
    },
    {
        "loss": 0.4963,
        "grad_norm": 5.599506855010986,
        "learning_rate": 1.8951310861423224e-05,
        "epoch": 0.26217228464419473,
        "step": 140
    },
    {
        "loss": 0.3773,
        "grad_norm": 6.4319586753845215,
        "learning_rate": 1.8876404494382024e-05,
        "epoch": 0.2808988764044944,
        "step": 150
    },
    {
        "loss": 0.5175,
        "grad_norm": 25.032106399536133,
        "learning_rate": 1.8801498127340823e-05,
        "epoch": 0.299625468164794,
        "step": 160
    },
    {
        "loss": 0.4624,
        "grad_norm": 12.849968910217285,
        "learning_rate": 1.8726591760299626e-05,
        "epoch": 0.31835205992509363,
        "step": 170
    },
    {
        "loss": 0.5422,
        "grad_norm": 5.523402214050293,
        "learning_rate": 1.8651685393258426e-05,
        "epoch": 0.33707865168539325,
        "step": 180
    },
    {
        "loss": 0.4903,
        "grad_norm": 7.17073917388916,
        "learning_rate": 1.8576779026217232e-05,
        "epoch": 0.35580524344569286,
        "step": 190
    },
    {
        "loss": 0.3934,
        "grad_norm": 8.953669548034668,
        "learning_rate": 1.8501872659176032e-05,
        "epoch": 0.37453183520599254,
        "step": 200
    },
    {
        "loss": 0.4524,
        "grad_norm": 8.359374046325684,
        "learning_rate": 1.8426966292134835e-05,
        "epoch": 0.39325842696629215,
        "step": 210
    },
    {
        "loss": 0.4172,
        "grad_norm": 5.626840591430664,
        "learning_rate": 1.8352059925093635e-05,
        "epoch": 0.41198501872659177,
        "step": 220
    },
    {
        "loss": 0.4359,
        "grad_norm": 4.890745162963867,
        "learning_rate": 1.8277153558052438e-05,
        "epoch": 0.4307116104868914,
        "step": 230
    },
    {
        "loss": 0.3544,
        "grad_norm": 6.640212535858154,
        "learning_rate": 1.8202247191011237e-05,
        "epoch": 0.449438202247191,
        "step": 240
    },
    {
        "loss": 0.4173,
        "grad_norm": 8.419635772705078,
        "learning_rate": 1.812734082397004e-05,
        "epoch": 0.4681647940074906,
        "step": 250
    },
    {
        "loss": 0.4702,
        "grad_norm": 5.260087013244629,
        "learning_rate": 1.805243445692884e-05,
        "epoch": 0.4868913857677903,
        "step": 260
    },
    {
        "loss": 0.5343,
        "grad_norm": 4.914426326751709,
        "learning_rate": 1.7977528089887643e-05,
        "epoch": 0.5056179775280899,
        "step": 270
    },
    {
        "loss": 0.4888,
        "grad_norm": 4.117834568023682,
        "learning_rate": 1.7902621722846443e-05,
        "epoch": 0.5243445692883895,
        "step": 280
    },
    {
        "loss": 0.4829,
        "grad_norm": 7.070493698120117,
        "learning_rate": 1.7827715355805242e-05,
        "epoch": 0.5430711610486891,
        "step": 290
    },
    {
        "loss": 0.4097,
        "grad_norm": 5.877195835113525,
        "learning_rate": 1.7752808988764045e-05,
        "epoch": 0.5617977528089888,
        "step": 300
    },
    {
        "loss": 0.3212,
        "grad_norm": 5.933269023895264,
        "learning_rate": 1.767790262172285e-05,
        "epoch": 0.5805243445692884,
        "step": 310
    },
    {
        "loss": 0.5148,
        "grad_norm": 24.675304412841797,
        "learning_rate": 1.760299625468165e-05,
        "epoch": 0.599250936329588,
        "step": 320
    },
    {
        "loss": 0.5033,
        "grad_norm": 6.069084644317627,
        "learning_rate": 1.752808988764045e-05,
        "epoch": 0.6179775280898876,
        "step": 330
    },
    {
        "loss": 0.3231,
        "grad_norm": 5.636498928070068,
        "learning_rate": 1.7453183520599254e-05,
        "epoch": 0.6367041198501873,
        "step": 340
    },
    {
        "loss": 0.4491,
        "grad_norm": 8.30411148071289,
        "learning_rate": 1.7378277153558054e-05,
        "epoch": 0.6554307116104869,
        "step": 350
    },
    {
        "loss": 0.3738,
        "grad_norm": 4.5501532554626465,
        "learning_rate": 1.7303370786516857e-05,
        "epoch": 0.6741573033707865,
        "step": 360
    },
    {
        "loss": 0.4283,
        "grad_norm": 12.638989448547363,
        "learning_rate": 1.7228464419475657e-05,
        "epoch": 0.6928838951310862,
        "step": 370
    },
    {
        "loss": 0.3913,
        "grad_norm": 5.383851528167725,
        "learning_rate": 1.715355805243446e-05,
        "epoch": 0.7116104868913857,
        "step": 380
    },
    {
        "loss": 0.5167,
        "grad_norm": 9.3871488571167,
        "learning_rate": 1.707865168539326e-05,
        "epoch": 0.7303370786516854,
        "step": 390
    },
    {
        "loss": 0.3818,
        "grad_norm": 12.088262557983398,
        "learning_rate": 1.7003745318352062e-05,
        "epoch": 0.7490636704119851,
        "step": 400
    },
    {
        "loss": 0.5052,
        "grad_norm": 3.40985107421875,
        "learning_rate": 1.6928838951310862e-05,
        "epoch": 0.7677902621722846,
        "step": 410
    },
    {
        "loss": 0.3643,
        "grad_norm": 8.60460090637207,
        "learning_rate": 1.6853932584269665e-05,
        "epoch": 0.7865168539325843,
        "step": 420
    },
    {
        "loss": 0.4283,
        "grad_norm": 5.848241806030273,
        "learning_rate": 1.6779026217228468e-05,
        "epoch": 0.8052434456928839,
        "step": 430
    },
    {
        "loss": 0.4002,
        "grad_norm": 6.872037410736084,
        "learning_rate": 1.6704119850187268e-05,
        "epoch": 0.8239700374531835,
        "step": 440
    },
    {
        "loss": 0.4332,
        "grad_norm": 5.427240371704102,
        "learning_rate": 1.662921348314607e-05,
        "epoch": 0.8426966292134831,
        "step": 450
    },
    {
        "loss": 0.4808,
        "grad_norm": 5.426667213439941,
        "learning_rate": 1.655430711610487e-05,
        "epoch": 0.8614232209737828,
        "step": 460
    },
    {
        "loss": 0.3915,
        "grad_norm": 13.884513854980469,
        "learning_rate": 1.6479400749063673e-05,
        "epoch": 0.8801498127340824,
        "step": 470
    },
    {
        "loss": 0.3539,
        "grad_norm": 8.328031539916992,
        "learning_rate": 1.6404494382022473e-05,
        "epoch": 0.898876404494382,
        "step": 480
    },
    {
        "loss": 0.3837,
        "grad_norm": 4.019711494445801,
        "learning_rate": 1.6329588014981276e-05,
        "epoch": 0.9176029962546817,
        "step": 490
    },
    {
        "loss": 0.3563,
        "grad_norm": 5.8874735832214355,
        "learning_rate": 1.6254681647940076e-05,
        "epoch": 0.9363295880149812,
        "step": 500
    },
    {
        "loss": 0.4635,
        "grad_norm": 8.21314525604248,
        "learning_rate": 1.617977528089888e-05,
        "epoch": 0.9550561797752809,
        "step": 510
    },
    {
        "loss": 0.4353,
        "grad_norm": 7.068436145782471,
        "learning_rate": 1.610486891385768e-05,
        "epoch": 0.9737827715355806,
        "step": 520
    },
    {
        "loss": 0.4319,
        "grad_norm": 12.392382621765137,
        "learning_rate": 1.602996254681648e-05,
        "epoch": 0.9925093632958801,
        "step": 530
    },
    {
        "eval_loss": 0.40517061948776245,
        "eval_accuracy": 0.8255159474671669,
        "eval_runtime": 5.0487,
        "eval_samples_per_second": 211.143,
        "eval_steps_per_second": 13.271,
        "epoch": 1.0,
        "step": 534
    },
    {
        "loss": 0.4299,
        "grad_norm": 6.429636001586914,
        "learning_rate": 1.595505617977528e-05,
        "epoch": 1.0112359550561798,
        "step": 540
    },
    {
        "loss": 0.4469,
        "grad_norm": 4.837648868560791,
        "learning_rate": 1.5880149812734084e-05,
        "epoch": 1.0299625468164795,
        "step": 550
    },
    {
        "loss": 0.4044,
        "grad_norm": 4.190347671508789,
        "learning_rate": 1.5805243445692887e-05,
        "epoch": 1.048689138576779,
        "step": 560
    },
    {
        "loss": 0.3623,
        "grad_norm": 8.999530792236328,
        "learning_rate": 1.5730337078651687e-05,
        "epoch": 1.0674157303370786,
        "step": 570
    },
    {
        "loss": 0.3896,
        "grad_norm": 9.133631706237793,
        "learning_rate": 1.565543071161049e-05,
        "epoch": 1.0861423220973783,
        "step": 580
    },
    {
        "loss": 0.3951,
        "grad_norm": 7.724978446960449,
        "learning_rate": 1.558052434456929e-05,
        "epoch": 1.104868913857678,
        "step": 590
    },
    {
        "loss": 0.3488,
        "grad_norm": 9.40996265411377,
        "learning_rate": 1.5505617977528093e-05,
        "epoch": 1.1235955056179776,
        "step": 600
    },
    {
        "loss": 0.3149,
        "grad_norm": 4.810867786407471,
        "learning_rate": 1.5430711610486892e-05,
        "epoch": 1.142322097378277,
        "step": 610
    },
    {
        "loss": 0.33,
        "grad_norm": 12.549762725830078,
        "learning_rate": 1.5355805243445695e-05,
        "epoch": 1.1610486891385767,
        "step": 620
    },
    {
        "loss": 0.4483,
        "grad_norm": 10.406655311584473,
        "learning_rate": 1.5280898876404495e-05,
        "epoch": 1.1797752808988764,
        "step": 630
    },
    {
        "loss": 0.3579,
        "grad_norm": 7.356879711151123,
        "learning_rate": 1.5205992509363296e-05,
        "epoch": 1.198501872659176,
        "step": 640
    },
    {
        "loss": 0.36,
        "grad_norm": 5.777255058288574,
        "learning_rate": 1.5131086142322098e-05,
        "epoch": 1.2172284644194757,
        "step": 650
    },
    {
        "loss": 0.3624,
        "grad_norm": 10.87370491027832,
        "learning_rate": 1.5056179775280899e-05,
        "epoch": 1.2359550561797752,
        "step": 660
    },
    {
        "loss": 0.398,
        "grad_norm": 3.781101703643799,
        "learning_rate": 1.4981273408239702e-05,
        "epoch": 1.2546816479400749,
        "step": 670
    },
    {
        "loss": 0.3757,
        "grad_norm": 9.148540496826172,
        "learning_rate": 1.4906367041198503e-05,
        "epoch": 1.2734082397003745,
        "step": 680
    },
    {
        "loss": 0.3881,
        "grad_norm": 5.600398063659668,
        "learning_rate": 1.4831460674157305e-05,
        "epoch": 1.2921348314606742,
        "step": 690
    },
    {
        "loss": 0.3186,
        "grad_norm": 6.478938102722168,
        "learning_rate": 1.4756554307116106e-05,
        "epoch": 1.3108614232209739,
        "step": 700
    },
    {
        "loss": 0.3834,
        "grad_norm": 6.261202335357666,
        "learning_rate": 1.4681647940074907e-05,
        "epoch": 1.3295880149812733,
        "step": 710
    },
    {
        "loss": 0.2739,
        "grad_norm": 5.813879489898682,
        "learning_rate": 1.4606741573033709e-05,
        "epoch": 1.348314606741573,
        "step": 720
    },
    {
        "loss": 0.3081,
        "grad_norm": 6.138799667358398,
        "learning_rate": 1.453183520599251e-05,
        "epoch": 1.3670411985018727,
        "step": 730
    },
    {
        "loss": 0.3694,
        "grad_norm": 4.0213799476623535,
        "learning_rate": 1.4456928838951311e-05,
        "epoch": 1.3857677902621723,
        "step": 740
    },
    {
        "loss": 0.3022,
        "grad_norm": 7.583944320678711,
        "learning_rate": 1.4382022471910113e-05,
        "epoch": 1.404494382022472,
        "step": 750
    },
    {
        "loss": 0.3152,
        "grad_norm": 4.717006683349609,
        "learning_rate": 1.4307116104868914e-05,
        "epoch": 1.4232209737827715,
        "step": 760
    },
    {
        "loss": 0.3242,
        "grad_norm": 7.135714530944824,
        "learning_rate": 1.4232209737827715e-05,
        "epoch": 1.4419475655430711,
        "step": 770
    },
    {
        "loss": 0.3274,
        "grad_norm": 11.097885131835938,
        "learning_rate": 1.4157303370786517e-05,
        "epoch": 1.4606741573033708,
        "step": 780
    },
    {
        "loss": 0.3034,
        "grad_norm": 6.094058513641357,
        "learning_rate": 1.408239700374532e-05,
        "epoch": 1.4794007490636705,
        "step": 790
    },
    {
        "loss": 0.4123,
        "grad_norm": 4.656342506408691,
        "learning_rate": 1.4007490636704121e-05,
        "epoch": 1.4981273408239701,
        "step": 800
    },
    {
        "loss": 0.3434,
        "grad_norm": 7.682201385498047,
        "learning_rate": 1.3932584269662923e-05,
        "epoch": 1.5168539325842696,
        "step": 810
    },
    {
        "loss": 0.3292,
        "grad_norm": 5.862093925476074,
        "learning_rate": 1.3857677902621724e-05,
        "epoch": 1.5355805243445693,
        "step": 820
    },
    {
        "loss": 0.3614,
        "grad_norm": 4.937498092651367,
        "learning_rate": 1.3782771535580525e-05,
        "epoch": 1.554307116104869,
        "step": 830
    },
    {
        "loss": 0.4036,
        "grad_norm": 17.847618103027344,
        "learning_rate": 1.3707865168539327e-05,
        "epoch": 1.5730337078651684,
        "step": 840
    },
    {
        "loss": 0.3716,
        "grad_norm": 7.459797382354736,
        "learning_rate": 1.3632958801498128e-05,
        "epoch": 1.5917602996254683,
        "step": 850
    },
    {
        "loss": 0.3705,
        "grad_norm": 5.166052341461182,
        "learning_rate": 1.355805243445693e-05,
        "epoch": 1.6104868913857677,
        "step": 860
    },
    {
        "loss": 0.3998,
        "grad_norm": 8.405563354492188,
        "learning_rate": 1.348314606741573e-05,
        "epoch": 1.6292134831460674,
        "step": 870
    },
    {
        "loss": 0.3449,
        "grad_norm": 3.6451244354248047,
        "learning_rate": 1.3408239700374532e-05,
        "epoch": 1.647940074906367,
        "step": 880
    },
    {
        "loss": 0.341,
        "grad_norm": 3.362578868865967,
        "learning_rate": 1.3333333333333333e-05,
        "epoch": 1.6666666666666665,
        "step": 890
    },
    {
        "loss": 0.3716,
        "grad_norm": 7.509115695953369,
        "learning_rate": 1.3258426966292135e-05,
        "epoch": 1.6853932584269664,
        "step": 900
    },
    {
        "loss": 0.2683,
        "grad_norm": 4.639886856079102,
        "learning_rate": 1.3183520599250936e-05,
        "epoch": 1.7041198501872659,
        "step": 910
    },
    {
        "loss": 0.3381,
        "grad_norm": 6.563561916351318,
        "learning_rate": 1.3108614232209739e-05,
        "epoch": 1.7228464419475655,
        "step": 920
    },
    {
        "loss": 0.372,
        "grad_norm": 6.9225850105285645,
        "learning_rate": 1.303370786516854e-05,
        "epoch": 1.7415730337078652,
        "step": 930
    },
    {
        "loss": 0.3771,
        "grad_norm": 7.871583461761475,
        "learning_rate": 1.2958801498127342e-05,
        "epoch": 1.7602996254681647,
        "step": 940
    },
    {
        "loss": 0.3113,
        "grad_norm": 6.578893661499023,
        "learning_rate": 1.2883895131086143e-05,
        "epoch": 1.7790262172284645,
        "step": 950
    },
    {
        "loss": 0.351,
        "grad_norm": 11.091743469238281,
        "learning_rate": 1.2808988764044944e-05,
        "epoch": 1.797752808988764,
        "step": 960
    },
    {
        "loss": 0.2776,
        "grad_norm": 7.049520015716553,
        "learning_rate": 1.2734082397003746e-05,
        "epoch": 1.8164794007490637,
        "step": 970
    },
    {
        "loss": 0.3588,
        "grad_norm": 3.537355661392212,
        "learning_rate": 1.2659176029962547e-05,
        "epoch": 1.8352059925093633,
        "step": 980
    },
    {
        "loss": 0.4206,
        "grad_norm": 14.642014503479004,
        "learning_rate": 1.2584269662921348e-05,
        "epoch": 1.8539325842696628,
        "step": 990
    },
    {
        "loss": 0.2454,
        "grad_norm": 3.614603042602539,
        "learning_rate": 1.250936329588015e-05,
        "epoch": 1.8726591760299627,
        "step": 1000
    },
    {
        "loss": 0.2997,
        "grad_norm": 8.928302764892578,
        "learning_rate": 1.2434456928838951e-05,
        "epoch": 1.8913857677902621,
        "step": 1010
    },
    {
        "loss": 0.4191,
        "grad_norm": 6.18691873550415,
        "learning_rate": 1.2359550561797752e-05,
        "epoch": 1.9101123595505618,
        "step": 1020
    },
    {
        "loss": 0.3344,
        "grad_norm": 6.989361763000488,
        "learning_rate": 1.2284644194756554e-05,
        "epoch": 1.9288389513108615,
        "step": 1030
    },
    {
        "loss": 0.3616,
        "grad_norm": 6.2137885093688965,
        "learning_rate": 1.2209737827715359e-05,
        "epoch": 1.947565543071161,
        "step": 1040
    },
    {
        "loss": 0.3352,
        "grad_norm": 6.187015533447266,
        "learning_rate": 1.213483146067416e-05,
        "epoch": 1.9662921348314608,
        "step": 1050
    },
    {
        "loss": 0.3183,
        "grad_norm": 5.5100884437561035,
        "learning_rate": 1.205992509363296e-05,
        "epoch": 1.9850187265917603,
        "step": 1060
    },
    {
        "eval_loss": 0.3150652050971985,
        "eval_accuracy": 0.8630393996247655,
        "eval_runtime": 5.0553,
        "eval_samples_per_second": 210.866,
        "eval_steps_per_second": 13.253,
        "epoch": 2.0,
        "step": 1068
    },
    {
        "loss": 0.3667,
        "grad_norm": 8.943591117858887,
        "learning_rate": 1.1985018726591761e-05,
        "epoch": 2.0037453183520597,
        "step": 1070
    },
    {
        "loss": 0.3299,
        "grad_norm": 5.29068660736084,
        "learning_rate": 1.1910112359550562e-05,
        "epoch": 2.0224719101123596,
        "step": 1080
    },
    {
        "loss": 0.4025,
        "grad_norm": 16.192575454711914,
        "learning_rate": 1.1835205992509364e-05,
        "epoch": 2.041198501872659,
        "step": 1090
    },
    {
        "loss": 0.3549,
        "grad_norm": 4.208759307861328,
        "learning_rate": 1.1760299625468165e-05,
        "epoch": 2.059925093632959,
        "step": 1100
    },
    {
        "loss": 0.3779,
        "grad_norm": 9.933672904968262,
        "learning_rate": 1.1685393258426966e-05,
        "epoch": 2.0786516853932584,
        "step": 1110
    },
    {
        "loss": 0.2575,
        "grad_norm": 4.087198257446289,
        "learning_rate": 1.1610486891385768e-05,
        "epoch": 2.097378277153558,
        "step": 1120
    },
    {
        "loss": 0.281,
        "grad_norm": 2.7885756492614746,
        "learning_rate": 1.1535580524344569e-05,
        "epoch": 2.1161048689138577,
        "step": 1130
    },
    {
        "loss": 0.3213,
        "grad_norm": 5.992141246795654,
        "learning_rate": 1.146067415730337e-05,
        "epoch": 2.134831460674157,
        "step": 1140
    },
    {
        "loss": 0.308,
        "grad_norm": 11.921051025390625,
        "learning_rate": 1.1385767790262172e-05,
        "epoch": 2.153558052434457,
        "step": 1150
    },
    {
        "loss": 0.3071,
        "grad_norm": 6.636651515960693,
        "learning_rate": 1.1310861423220976e-05,
        "epoch": 2.1722846441947565,
        "step": 1160
    },
    {
        "loss": 0.3408,
        "grad_norm": 8.06382942199707,
        "learning_rate": 1.1235955056179778e-05,
        "epoch": 2.191011235955056,
        "step": 1170
    },
    {
        "loss": 0.3564,
        "grad_norm": 6.802521228790283,
        "learning_rate": 1.1161048689138579e-05,
        "epoch": 2.209737827715356,
        "step": 1180
    },
    {
        "loss": 0.3099,
        "grad_norm": 5.754052639007568,
        "learning_rate": 1.108614232209738e-05,
        "epoch": 2.2284644194756553,
        "step": 1190
    },
    {
        "loss": 0.3595,
        "grad_norm": 4.6640119552612305,
        "learning_rate": 1.101123595505618e-05,
        "epoch": 2.247191011235955,
        "step": 1200
    },
    {
        "loss": 0.3173,
        "grad_norm": 5.867389678955078,
        "learning_rate": 1.0936329588014981e-05,
        "epoch": 2.2659176029962547,
        "step": 1210
    },
    {
        "loss": 0.2727,
        "grad_norm": 2.9115521907806396,
        "learning_rate": 1.0861423220973783e-05,
        "epoch": 2.284644194756554,
        "step": 1220
    },
    {
        "loss": 0.4655,
        "grad_norm": 6.656843662261963,
        "learning_rate": 1.0786516853932584e-05,
        "epoch": 2.303370786516854,
        "step": 1230
    },
    {
        "loss": 0.2938,
        "grad_norm": 4.650968074798584,
        "learning_rate": 1.0711610486891385e-05,
        "epoch": 2.3220973782771535,
        "step": 1240
    },
    {
        "loss": 0.3591,
        "grad_norm": 5.820017337799072,
        "learning_rate": 1.0636704119850187e-05,
        "epoch": 2.3408239700374533,
        "step": 1250
    },
    {
        "loss": 0.3147,
        "grad_norm": 5.3731489181518555,
        "learning_rate": 1.0561797752808988e-05,
        "epoch": 2.359550561797753,
        "step": 1260
    },
    {
        "loss": 0.4025,
        "grad_norm": 11.995017051696777,
        "learning_rate": 1.048689138576779e-05,
        "epoch": 2.3782771535580522,
        "step": 1270
    },
    {
        "loss": 0.3205,
        "grad_norm": 6.771066665649414,
        "learning_rate": 1.0411985018726594e-05,
        "epoch": 2.397003745318352,
        "step": 1280
    },
    {
        "loss": 0.2944,
        "grad_norm": 7.424070358276367,
        "learning_rate": 1.0337078651685396e-05,
        "epoch": 2.4157303370786516,
        "step": 1290
    },
    {
        "loss": 0.2981,
        "grad_norm": 5.204805850982666,
        "learning_rate": 1.0262172284644197e-05,
        "epoch": 2.4344569288389515,
        "step": 1300
    },
    {
        "loss": 0.2548,
        "grad_norm": 7.791659832000732,
        "learning_rate": 1.0187265917602998e-05,
        "epoch": 2.453183520599251,
        "step": 1310
    },
    {
        "loss": 0.3437,
        "grad_norm": 11.58285140991211,
        "learning_rate": 1.01123595505618e-05,
        "epoch": 2.4719101123595504,
        "step": 1320
    },
    {
        "loss": 0.2847,
        "grad_norm": 5.628049850463867,
        "learning_rate": 1.0037453183520601e-05,
        "epoch": 2.4906367041198503,
        "step": 1330
    },
    {
        "loss": 0.3187,
        "grad_norm": 4.575004577636719,
        "learning_rate": 9.9625468164794e-06,
        "epoch": 2.5093632958801497,
        "step": 1340
    },
    {
        "loss": 0.2487,
        "grad_norm": 3.142016887664795,
        "learning_rate": 9.887640449438202e-06,
        "epoch": 2.5280898876404496,
        "step": 1350
    },
    {
        "loss": 0.2767,
        "grad_norm": 10.900567054748535,
        "learning_rate": 9.812734082397003e-06,
        "epoch": 2.546816479400749,
        "step": 1360
    },
    {
        "loss": 0.2688,
        "grad_norm": 4.780420780181885,
        "learning_rate": 9.737827715355806e-06,
        "epoch": 2.5655430711610485,
        "step": 1370
    },
    {
        "loss": 0.2832,
        "grad_norm": 12.277155876159668,
        "learning_rate": 9.662921348314608e-06,
        "epoch": 2.5842696629213484,
        "step": 1380
    },
    {
        "loss": 0.2953,
        "grad_norm": 6.991446495056152,
        "learning_rate": 9.588014981273409e-06,
        "epoch": 2.602996254681648,
        "step": 1390
    },
    {
        "loss": 0.2663,
        "grad_norm": 8.347607612609863,
        "learning_rate": 9.51310861423221e-06,
        "epoch": 2.6217228464419478,
        "step": 1400
    },
    {
        "loss": 0.3294,
        "grad_norm": 11.765824317932129,
        "learning_rate": 9.438202247191012e-06,
        "epoch": 2.640449438202247,
        "step": 1410
    },
    {
        "loss": 0.3187,
        "grad_norm": 5.972076416015625,
        "learning_rate": 9.363295880149813e-06,
        "epoch": 2.6591760299625467,
        "step": 1420
    },
    {
        "loss": 0.2924,
        "grad_norm": 9.920714378356934,
        "learning_rate": 9.288389513108616e-06,
        "epoch": 2.6779026217228465,
        "step": 1430
    },
    {
        "loss": 0.3566,
        "grad_norm": 6.299309730529785,
        "learning_rate": 9.213483146067417e-06,
        "epoch": 2.696629213483146,
        "step": 1440
    },
    {
        "loss": 0.3665,
        "grad_norm": 7.20506477355957,
        "learning_rate": 9.138576779026219e-06,
        "epoch": 2.715355805243446,
        "step": 1450
    },
    {
        "loss": 0.2607,
        "grad_norm": 3.6992671489715576,
        "learning_rate": 9.06367041198502e-06,
        "epoch": 2.7340823970037453,
        "step": 1460
    },
    {
        "loss": 0.3042,
        "grad_norm": 2.873072385787964,
        "learning_rate": 8.988764044943822e-06,
        "epoch": 2.752808988764045,
        "step": 1470
    },
    {
        "loss": 0.2745,
        "grad_norm": 3.111227035522461,
        "learning_rate": 8.913857677902621e-06,
        "epoch": 2.7715355805243447,
        "step": 1480
    },
    {
        "loss": 0.2852,
        "grad_norm": 5.1113739013671875,
        "learning_rate": 8.838951310861424e-06,
        "epoch": 2.790262172284644,
        "step": 1490
    },
    {
        "loss": 0.4102,
        "grad_norm": 7.8445844650268555,
        "learning_rate": 8.764044943820226e-06,
        "epoch": 2.808988764044944,
        "step": 1500
    },
    {
        "loss": 0.2454,
        "grad_norm": 5.494629859924316,
        "learning_rate": 8.689138576779027e-06,
        "epoch": 2.8277153558052435,
        "step": 1510
    },
    {
        "loss": 0.2456,
        "grad_norm": 7.653980731964111,
        "learning_rate": 8.614232209737828e-06,
        "epoch": 2.846441947565543,
        "step": 1520
    },
    {
        "loss": 0.355,
        "grad_norm": 7.716179847717285,
        "learning_rate": 8.53932584269663e-06,
        "epoch": 2.865168539325843,
        "step": 1530
    },
    {
        "loss": 0.323,
        "grad_norm": 4.497408866882324,
        "learning_rate": 8.464419475655431e-06,
        "epoch": 2.8838951310861423,
        "step": 1540
    },
    {
        "loss": 0.3084,
        "grad_norm": 10.040885925292969,
        "learning_rate": 8.389513108614234e-06,
        "epoch": 2.902621722846442,
        "step": 1550
    },
    {
        "loss": 0.3107,
        "grad_norm": 7.072617530822754,
        "learning_rate": 8.314606741573035e-06,
        "epoch": 2.9213483146067416,
        "step": 1560
    },
    {
        "loss": 0.3575,
        "grad_norm": 11.353636741638184,
        "learning_rate": 8.239700374531837e-06,
        "epoch": 2.940074906367041,
        "step": 1570
    },
    {
        "loss": 0.287,
        "grad_norm": 7.846920490264893,
        "learning_rate": 8.164794007490638e-06,
        "epoch": 2.958801498127341,
        "step": 1580
    },
    {
        "loss": 0.3054,
        "grad_norm": 3.453545093536377,
        "learning_rate": 8.08988764044944e-06,
        "epoch": 2.9775280898876404,
        "step": 1590
    },
    {
        "loss": 0.3058,
        "grad_norm": 4.674100399017334,
        "learning_rate": 8.01498127340824e-06,
        "epoch": 2.9962546816479403,
        "step": 1600
    },
    {
        "eval_loss": 0.31315603852272034,
        "eval_accuracy": 0.8686679174484052,
        "eval_runtime": 5.0138,
        "eval_samples_per_second": 212.613,
        "eval_steps_per_second": 13.363,
        "epoch": 3.0,
        "step": 1602
    },
    {
        "loss": 0.2259,
        "grad_norm": 4.211068630218506,
        "learning_rate": 7.940074906367042e-06,
        "epoch": 3.0149812734082397,
        "step": 1610
    },
    {
        "loss": 0.2304,
        "grad_norm": 12.62403392791748,
        "learning_rate": 7.865168539325843e-06,
        "epoch": 3.033707865168539,
        "step": 1620
    },
    {
        "loss": 0.2269,
        "grad_norm": 5.900755405426025,
        "learning_rate": 7.790262172284645e-06,
        "epoch": 3.052434456928839,
        "step": 1630
    },
    {
        "loss": 0.2056,
        "grad_norm": 5.385382175445557,
        "learning_rate": 7.715355805243446e-06,
        "epoch": 3.0711610486891385,
        "step": 1640
    },
    {
        "loss": 0.3312,
        "grad_norm": 15.044760704040527,
        "learning_rate": 7.640449438202247e-06,
        "epoch": 3.0898876404494384,
        "step": 1650
    },
    {
        "loss": 0.2521,
        "grad_norm": 5.267138481140137,
        "learning_rate": 7.565543071161049e-06,
        "epoch": 3.108614232209738,
        "step": 1660
    },
    {
        "loss": 0.2154,
        "grad_norm": 5.782016277313232,
        "learning_rate": 7.490636704119851e-06,
        "epoch": 3.1273408239700373,
        "step": 1670
    },
    {
        "loss": 0.3799,
        "grad_norm": 9.428120613098145,
        "learning_rate": 7.415730337078652e-06,
        "epoch": 3.146067415730337,
        "step": 1680
    },
    {
        "loss": 0.2618,
        "grad_norm": 5.587920665740967,
        "learning_rate": 7.340823970037454e-06,
        "epoch": 3.1647940074906367,
        "step": 1690
    },
    {
        "loss": 0.3161,
        "grad_norm": 7.044327259063721,
        "learning_rate": 7.265917602996255e-06,
        "epoch": 3.1835205992509366,
        "step": 1700
    },
    {
        "loss": 0.27,
        "grad_norm": 11.382105827331543,
        "learning_rate": 7.191011235955056e-06,
        "epoch": 3.202247191011236,
        "step": 1710
    },
    {
        "loss": 0.2384,
        "grad_norm": 6.817880153656006,
        "learning_rate": 7.116104868913858e-06,
        "epoch": 3.2209737827715355,
        "step": 1720
    },
    {
        "loss": 0.2904,
        "grad_norm": 6.066442966461182,
        "learning_rate": 7.04119850187266e-06,
        "epoch": 3.2397003745318353,
        "step": 1730
    },
    {
        "loss": 0.2771,
        "grad_norm": 5.876824855804443,
        "learning_rate": 6.966292134831461e-06,
        "epoch": 3.258426966292135,
        "step": 1740
    },
    {
        "loss": 0.3217,
        "grad_norm": 4.882170677185059,
        "learning_rate": 6.891385767790263e-06,
        "epoch": 3.2771535580524347,
        "step": 1750
    },
    {
        "loss": 0.2051,
        "grad_norm": 4.104053020477295,
        "learning_rate": 6.816479400749064e-06,
        "epoch": 3.295880149812734,
        "step": 1760
    },
    {
        "loss": 0.2979,
        "grad_norm": 9.202933311462402,
        "learning_rate": 6.741573033707865e-06,
        "epoch": 3.3146067415730336,
        "step": 1770
    },
    {
        "loss": 0.3306,
        "grad_norm": 4.706033706665039,
        "learning_rate": 6.666666666666667e-06,
        "epoch": 3.3333333333333335,
        "step": 1780
    },
    {
        "loss": 0.1977,
        "grad_norm": 7.7561821937561035,
        "learning_rate": 6.591760299625468e-06,
        "epoch": 3.352059925093633,
        "step": 1790
    },
    {
        "loss": 0.2312,
        "grad_norm": 6.649930477142334,
        "learning_rate": 6.51685393258427e-06,
        "epoch": 3.370786516853933,
        "step": 1800
    },
    {
        "loss": 0.163,
        "grad_norm": 6.372569561004639,
        "learning_rate": 6.4419475655430715e-06,
        "epoch": 3.3895131086142323,
        "step": 1810
    },
    {
        "loss": 0.23,
        "grad_norm": 5.2756524085998535,
        "learning_rate": 6.367041198501873e-06,
        "epoch": 3.4082397003745317,
        "step": 1820
    },
    {
        "loss": 0.1956,
        "grad_norm": 4.133210182189941,
        "learning_rate": 6.292134831460674e-06,
        "epoch": 3.4269662921348316,
        "step": 1830
    },
    {
        "loss": 0.2878,
        "grad_norm": 6.4562273025512695,
        "learning_rate": 6.2172284644194756e-06,
        "epoch": 3.445692883895131,
        "step": 1840
    },
    {
        "loss": 0.31,
        "grad_norm": 10.126419067382812,
        "learning_rate": 6.142322097378277e-06,
        "epoch": 3.464419475655431,
        "step": 1850
    },
    {
        "loss": 0.3087,
        "grad_norm": 5.522005558013916,
        "learning_rate": 6.06741573033708e-06,
        "epoch": 3.4831460674157304,
        "step": 1860
    },
    {
        "loss": 0.4085,
        "grad_norm": 4.267848491668701,
        "learning_rate": 5.9925093632958805e-06,
        "epoch": 3.50187265917603,
        "step": 1870
    },
    {
        "loss": 0.2861,
        "grad_norm": 3.9821112155914307,
        "learning_rate": 5.917602996254682e-06,
        "epoch": 3.5205992509363297,
        "step": 1880
    },
    {
        "loss": 0.3254,
        "grad_norm": 6.267520904541016,
        "learning_rate": 5.842696629213483e-06,
        "epoch": 3.539325842696629,
        "step": 1890
    },
    {
        "loss": 0.2277,
        "grad_norm": 4.809154510498047,
        "learning_rate": 5.7677902621722845e-06,
        "epoch": 3.558052434456929,
        "step": 1900
    },
    {
        "loss": 0.2686,
        "grad_norm": 3.0375490188598633,
        "learning_rate": 5.692883895131086e-06,
        "epoch": 3.5767790262172285,
        "step": 1910
    },
    {
        "loss": 0.3248,
        "grad_norm": 6.28224515914917,
        "learning_rate": 5.617977528089889e-06,
        "epoch": 3.595505617977528,
        "step": 1920
    },
    {
        "loss": 0.3107,
        "grad_norm": 4.505108833312988,
        "learning_rate": 5.54307116104869e-06,
        "epoch": 3.6142322097378274,
        "step": 1930
    },
    {
        "loss": 0.2611,
        "grad_norm": 7.141664505004883,
        "learning_rate": 5.468164794007491e-06,
        "epoch": 3.6329588014981273,
        "step": 1940
    },
    {
        "loss": 0.3417,
        "grad_norm": 10.546417236328125,
        "learning_rate": 5.393258426966292e-06,
        "epoch": 3.6516853932584272,
        "step": 1950
    },
    {
        "loss": 0.2857,
        "grad_norm": 6.23655366897583,
        "learning_rate": 5.318352059925093e-06,
        "epoch": 3.6704119850187267,
        "step": 1960
    },
    {
        "loss": 0.29,
        "grad_norm": 5.03485107421875,
        "learning_rate": 5.243445692883895e-06,
        "epoch": 3.689138576779026,
        "step": 1970
    },
    {
        "loss": 0.3444,
        "grad_norm": 10.440464973449707,
        "learning_rate": 5.168539325842698e-06,
        "epoch": 3.7078651685393256,
        "step": 1980
    },
    {
        "loss": 0.2276,
        "grad_norm": 5.773072242736816,
        "learning_rate": 5.093632958801499e-06,
        "epoch": 3.7265917602996255,
        "step": 1990
    },
    {
        "loss": 0.3173,
        "grad_norm": 7.093286514282227,
        "learning_rate": 5.0187265917603005e-06,
        "epoch": 3.7453183520599254,
        "step": 2000
    },
    {
        "loss": 0.1746,
        "grad_norm": 5.221498966217041,
        "learning_rate": 4.943820224719101e-06,
        "epoch": 3.764044943820225,
        "step": 2010
    },
    {
        "loss": 0.3252,
        "grad_norm": 5.6883368492126465,
        "learning_rate": 4.868913857677903e-06,
        "epoch": 3.7827715355805243,
        "step": 2020
    },
    {
        "loss": 0.3396,
        "grad_norm": 9.500866889953613,
        "learning_rate": 4.7940074906367045e-06,
        "epoch": 3.8014981273408237,
        "step": 2030
    },
    {
        "loss": 0.2845,
        "grad_norm": 10.015218734741211,
        "learning_rate": 4.719101123595506e-06,
        "epoch": 3.8202247191011236,
        "step": 2040
    },
    {
        "loss": 0.4024,
        "grad_norm": 4.4756245613098145,
        "learning_rate": 4.644194756554308e-06,
        "epoch": 3.8389513108614235,
        "step": 2050
    },
    {
        "loss": 0.2266,
        "grad_norm": 6.147637844085693,
        "learning_rate": 4.569288389513109e-06,
        "epoch": 3.857677902621723,
        "step": 2060
    },
    {
        "loss": 0.2521,
        "grad_norm": 4.044114589691162,
        "learning_rate": 4.494382022471911e-06,
        "epoch": 3.8764044943820224,
        "step": 2070
    },
    {
        "loss": 0.2537,
        "grad_norm": 2.5167136192321777,
        "learning_rate": 4.419475655430712e-06,
        "epoch": 3.895131086142322,
        "step": 2080
    },
    {
        "loss": 0.2513,
        "grad_norm": 4.090114593505859,
        "learning_rate": 4.3445692883895135e-06,
        "epoch": 3.9138576779026217,
        "step": 2090
    },
    {
        "loss": 0.2866,
        "grad_norm": 3.463120222091675,
        "learning_rate": 4.269662921348315e-06,
        "epoch": 3.932584269662921,
        "step": 2100
    },
    {
        "loss": 0.2802,
        "grad_norm": 8.338831901550293,
        "learning_rate": 4.194756554307117e-06,
        "epoch": 3.951310861423221,
        "step": 2110
    },
    {
        "loss": 0.2696,
        "grad_norm": 13.238082885742188,
        "learning_rate": 4.119850187265918e-06,
        "epoch": 3.9700374531835205,
        "step": 2120
    },
    {
        "loss": 0.2338,
        "grad_norm": 5.7436933517456055,
        "learning_rate": 4.04494382022472e-06,
        "epoch": 3.98876404494382,
        "step": 2130
    },
    {
        "eval_loss": 0.3149230182170868,
        "eval_accuracy": 0.8714821763602252,
        "eval_runtime": 4.981,
        "eval_samples_per_second": 214.012,
        "eval_steps_per_second": 13.451,
        "epoch": 4.0,
        "step": 2136
    },
    {
        "loss": 0.2207,
        "grad_norm": 6.6623454093933105,
        "learning_rate": 3.970037453183521e-06,
        "epoch": 4.007490636704119,
        "step": 2140
    },
    {
        "loss": 0.2722,
        "grad_norm": 7.832186698913574,
        "learning_rate": 3.895131086142322e-06,
        "epoch": 4.02621722846442,
        "step": 2150
    },
    {
        "loss": 0.2591,
        "grad_norm": 4.774863243103027,
        "learning_rate": 3.820224719101124e-06,
        "epoch": 4.044943820224719,
        "step": 2160
    },
    {
        "loss": 0.2762,
        "grad_norm": 4.098659515380859,
        "learning_rate": 3.7453183520599255e-06,
        "epoch": 4.063670411985019,
        "step": 2170
    },
    {
        "loss": 0.1365,
        "grad_norm": 3.1465606689453125,
        "learning_rate": 3.670411985018727e-06,
        "epoch": 4.082397003745318,
        "step": 2180
    },
    {
        "loss": 0.2455,
        "grad_norm": 5.300580024719238,
        "learning_rate": 3.595505617977528e-06,
        "epoch": 4.101123595505618,
        "step": 2190
    },
    {
        "loss": 0.2595,
        "grad_norm": 5.1971588134765625,
        "learning_rate": 3.52059925093633e-06,
        "epoch": 4.119850187265918,
        "step": 2200
    },
    {
        "loss": 0.2748,
        "grad_norm": 5.866971492767334,
        "learning_rate": 3.4456928838951313e-06,
        "epoch": 4.138576779026217,
        "step": 2210
    },
    {
        "loss": 0.1891,
        "grad_norm": 10.666412353515625,
        "learning_rate": 3.3707865168539327e-06,
        "epoch": 4.157303370786517,
        "step": 2220
    },
    {
        "loss": 0.2893,
        "grad_norm": 7.450674533843994,
        "learning_rate": 3.295880149812734e-06,
        "epoch": 4.176029962546816,
        "step": 2230
    },
    {
        "loss": 0.2292,
        "grad_norm": 7.367231845855713,
        "learning_rate": 3.2209737827715358e-06,
        "epoch": 4.194756554307116,
        "step": 2240
    },
    {
        "loss": 0.234,
        "grad_norm": 11.56586742401123,
        "learning_rate": 3.146067415730337e-06,
        "epoch": 4.213483146067416,
        "step": 2250
    },
    {
        "loss": 0.1746,
        "grad_norm": 6.4844441413879395,
        "learning_rate": 3.0711610486891385e-06,
        "epoch": 4.2322097378277155,
        "step": 2260
    },
    {
        "loss": 0.1838,
        "grad_norm": 5.235843181610107,
        "learning_rate": 2.9962546816479402e-06,
        "epoch": 4.250936329588015,
        "step": 2270
    },
    {
        "loss": 0.2536,
        "grad_norm": 6.277548313140869,
        "learning_rate": 2.9213483146067416e-06,
        "epoch": 4.269662921348314,
        "step": 2280
    },
    {
        "loss": 0.312,
        "grad_norm": 19.801362991333008,
        "learning_rate": 2.846441947565543e-06,
        "epoch": 4.288389513108614,
        "step": 2290
    },
    {
        "loss": 0.2377,
        "grad_norm": 4.869266510009766,
        "learning_rate": 2.771535580524345e-06,
        "epoch": 4.307116104868914,
        "step": 2300
    },
    {
        "loss": 0.2781,
        "grad_norm": 6.993345737457275,
        "learning_rate": 2.696629213483146e-06,
        "epoch": 4.325842696629214,
        "step": 2310
    },
    {
        "loss": 0.2627,
        "grad_norm": 3.736013650894165,
        "learning_rate": 2.6217228464419474e-06,
        "epoch": 4.344569288389513,
        "step": 2320
    },
    {
        "loss": 0.2662,
        "grad_norm": 5.03386116027832,
        "learning_rate": 2.5468164794007496e-06,
        "epoch": 4.3632958801498125,
        "step": 2330
    },
    {
        "loss": 0.276,
        "grad_norm": 4.55278205871582,
        "learning_rate": 2.4719101123595505e-06,
        "epoch": 4.382022471910112,
        "step": 2340
    },
    {
        "loss": 0.2699,
        "grad_norm": 7.116333484649658,
        "learning_rate": 2.3970037453183523e-06,
        "epoch": 4.400749063670412,
        "step": 2350
    },
    {
        "loss": 0.2414,
        "grad_norm": 5.2798848152160645,
        "learning_rate": 2.322097378277154e-06,
        "epoch": 4.419475655430712,
        "step": 2360
    },
    {
        "loss": 0.2361,
        "grad_norm": 6.6660966873168945,
        "learning_rate": 2.2471910112359554e-06,
        "epoch": 4.438202247191011,
        "step": 2370
    },
    {
        "loss": 0.307,
        "grad_norm": 11.54343032836914,
        "learning_rate": 2.1722846441947567e-06,
        "epoch": 4.456928838951311,
        "step": 2380
    },
    {
        "loss": 0.3375,
        "grad_norm": 9.11019515991211,
        "learning_rate": 2.0973782771535585e-06,
        "epoch": 4.47565543071161,
        "step": 2390
    },
    {
        "loss": 0.171,
        "grad_norm": 1.702224612236023,
        "learning_rate": 2.02247191011236e-06,
        "epoch": 4.49438202247191,
        "step": 2400
    },
    {
        "loss": 0.371,
        "grad_norm": 11.46294116973877,
        "learning_rate": 1.947565543071161e-06,
        "epoch": 4.51310861423221,
        "step": 2410
    },
    {
        "loss": 0.242,
        "grad_norm": 9.669544219970703,
        "learning_rate": 1.8726591760299627e-06,
        "epoch": 4.531835205992509,
        "step": 2420
    },
    {
        "loss": 0.2125,
        "grad_norm": 11.658425331115723,
        "learning_rate": 1.797752808988764e-06,
        "epoch": 4.550561797752809,
        "step": 2430
    },
    {
        "loss": 0.2497,
        "grad_norm": 8.287044525146484,
        "learning_rate": 1.7228464419475657e-06,
        "epoch": 4.569288389513108,
        "step": 2440
    },
    {
        "loss": 0.2487,
        "grad_norm": 11.761821746826172,
        "learning_rate": 1.647940074906367e-06,
        "epoch": 4.588014981273409,
        "step": 2450
    },
    {
        "loss": 0.2189,
        "grad_norm": 3.90620756149292,
        "learning_rate": 1.5730337078651686e-06,
        "epoch": 4.606741573033708,
        "step": 2460
    },
    {
        "loss": 0.2787,
        "grad_norm": 3.563291072845459,
        "learning_rate": 1.4981273408239701e-06,
        "epoch": 4.6254681647940075,
        "step": 2470
    },
    {
        "loss": 0.2683,
        "grad_norm": 10.774589538574219,
        "learning_rate": 1.4232209737827715e-06,
        "epoch": 4.644194756554307,
        "step": 2480
    },
    {
        "loss": 0.2845,
        "grad_norm": 7.1377739906311035,
        "learning_rate": 1.348314606741573e-06,
        "epoch": 4.662921348314606,
        "step": 2490
    },
    {
        "loss": 0.1762,
        "grad_norm": 4.665164947509766,
        "learning_rate": 1.2734082397003748e-06,
        "epoch": 4.681647940074907,
        "step": 2500
    },
    {
        "loss": 0.2765,
        "grad_norm": 7.99069881439209,
        "learning_rate": 1.1985018726591761e-06,
        "epoch": 4.700374531835206,
        "step": 2510
    },
    {
        "loss": 0.1816,
        "grad_norm": 6.233978271484375,
        "learning_rate": 1.1235955056179777e-06,
        "epoch": 4.719101123595506,
        "step": 2520
    },
    {
        "loss": 0.2591,
        "grad_norm": 2.952965497970581,
        "learning_rate": 1.0486891385767792e-06,
        "epoch": 4.737827715355805,
        "step": 2530
    },
    {
        "loss": 0.1881,
        "grad_norm": 4.02583646774292,
        "learning_rate": 9.737827715355806e-07,
        "epoch": 4.7565543071161045,
        "step": 2540
    },
    {
        "loss": 0.3592,
        "grad_norm": 3.066997766494751,
        "learning_rate": 8.98876404494382e-07,
        "epoch": 4.775280898876405,
        "step": 2550
    },
    {
        "loss": 0.2311,
        "grad_norm": 5.448582649230957,
        "learning_rate": 8.239700374531835e-07,
        "epoch": 4.794007490636704,
        "step": 2560
    },
    {
        "loss": 0.3211,
        "grad_norm": 8.07402515411377,
        "learning_rate": 7.490636704119851e-07,
        "epoch": 4.812734082397004,
        "step": 2570
    },
    {
        "loss": 0.216,
        "grad_norm": 5.582842826843262,
        "learning_rate": 6.741573033707865e-07,
        "epoch": 4.831460674157303,
        "step": 2580
    },
    {
        "loss": 0.2031,
        "grad_norm": 7.867647647857666,
        "learning_rate": 5.992509363295881e-07,
        "epoch": 4.850187265917603,
        "step": 2590
    },
    {
        "loss": 0.3228,
        "grad_norm": 8.980655670166016,
        "learning_rate": 5.243445692883896e-07,
        "epoch": 4.868913857677903,
        "step": 2600
    },
    {
        "loss": 0.2096,
        "grad_norm": 2.031492233276367,
        "learning_rate": 4.49438202247191e-07,
        "epoch": 4.887640449438202,
        "step": 2610
    },
    {
        "loss": 0.3603,
        "grad_norm": 5.496667861938477,
        "learning_rate": 3.7453183520599253e-07,
        "epoch": 4.906367041198502,
        "step": 2620
    },
    {
        "loss": 0.1947,
        "grad_norm": 7.808209419250488,
        "learning_rate": 2.9962546816479403e-07,
        "epoch": 4.925093632958801,
        "step": 2630
    },
    {
        "loss": 0.2184,
        "grad_norm": 8.297086715698242,
        "learning_rate": 2.247191011235955e-07,
        "epoch": 4.943820224719101,
        "step": 2640
    },
    {
        "loss": 0.2111,
        "grad_norm": 4.225507736206055,
        "learning_rate": 1.4981273408239702e-07,
        "epoch": 4.962546816479401,
        "step": 2650
    },
    {
        "loss": 0.2988,
        "grad_norm": 4.450363636016846,
        "learning_rate": 7.490636704119851e-08,
        "epoch": 4.9812734082397006,
        "step": 2660
    },
    {
        "loss": 0.3556,
        "grad_norm": 54.05887222290039,
        "learning_rate": 0.0,
        "epoch": 5.0,
        "step": 2670
    },
    {
        "eval_loss": 0.34112489223480225,
        "eval_accuracy": 0.8602251407129456,
        "eval_runtime": 7.6072,
        "eval_samples_per_second": 140.13,
        "eval_steps_per_second": 8.807,
        "epoch": 5.0,
        "step": 2670
    },
    {
        "train_runtime": 708.4582,
        "train_samples_per_second": 60.201,
        "train_steps_per_second": 3.769,
        "total_flos": 1663467169480704.0,
        "train_loss": 0.33576811596695405,
        "epoch": 5.0,
        "step": 2670
    },
    {
        "eval_loss": 0.3470243811607361,
        "eval_accuracy": 0.8611632270168855,
        "eval_runtime": 4.5798,
        "eval_samples_per_second": 232.76,
        "eval_steps_per_second": 14.629,
        "epoch": 5.0,
        "step": 2670
    },
    {
        "eval_loss": 0.3470243811607361,
        "eval_accuracy": 0.8611632270168855,
        "eval_runtime": 4.0292,
        "eval_samples_per_second": 264.567,
        "eval_steps_per_second": 16.628,
        "epoch": 5.0,
        "step": 2670
    }
]