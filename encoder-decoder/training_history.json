[
    {
        "loss": 4.3742,
        "grad_norm": 29.176910400390625,
        "learning_rate": 1.9875156054931336e-05,
        "epoch": 0.018726591760299626,
        "step": 10
    },
    {
        "loss": 2.5412,
        "grad_norm": 15.313116073608398,
        "learning_rate": 1.9750312109862673e-05,
        "epoch": 0.03745318352059925,
        "step": 20
    },
    {
        "loss": 1.4772,
        "grad_norm": 9.893752098083496,
        "learning_rate": 1.9625468164794007e-05,
        "epoch": 0.056179775280898875,
        "step": 30
    },
    {
        "loss": 0.8918,
        "grad_norm": 8.050333976745605,
        "learning_rate": 1.9500624219725347e-05,
        "epoch": 0.0749063670411985,
        "step": 40
    },
    {
        "loss": 0.5351,
        "grad_norm": 3.9786343574523926,
        "learning_rate": 1.937578027465668e-05,
        "epoch": 0.09363295880149813,
        "step": 50
    },
    {
        "loss": 0.2502,
        "grad_norm": 5.7948222160339355,
        "learning_rate": 1.925093632958802e-05,
        "epoch": 0.11235955056179775,
        "step": 60
    },
    {
        "loss": 0.0943,
        "grad_norm": 1.880925178527832,
        "learning_rate": 1.9126092384519352e-05,
        "epoch": 0.13108614232209737,
        "step": 70
    },
    {
        "loss": 0.0773,
        "grad_norm": 0.4953949749469757,
        "learning_rate": 1.900124843945069e-05,
        "epoch": 0.149812734082397,
        "step": 80
    },
    {
        "loss": 0.0708,
        "grad_norm": 0.46882930397987366,
        "learning_rate": 1.8876404494382024e-05,
        "epoch": 0.16853932584269662,
        "step": 90
    },
    {
        "loss": 0.0582,
        "grad_norm": 0.4856569170951843,
        "learning_rate": 1.8751560549313357e-05,
        "epoch": 0.18726591760299627,
        "step": 100
    },
    {
        "loss": 0.0509,
        "grad_norm": 1.3328547477722168,
        "learning_rate": 1.8626716604244698e-05,
        "epoch": 0.20599250936329588,
        "step": 110
    },
    {
        "loss": 0.054,
        "grad_norm": 1.604675054550171,
        "learning_rate": 1.8501872659176032e-05,
        "epoch": 0.2247191011235955,
        "step": 120
    },
    {
        "loss": 0.0582,
        "grad_norm": 0.460550993680954,
        "learning_rate": 1.837702871410737e-05,
        "epoch": 0.24344569288389514,
        "step": 130
    },
    {
        "loss": 0.0513,
        "grad_norm": 0.4531446099281311,
        "learning_rate": 1.8252184769038703e-05,
        "epoch": 0.26217228464419473,
        "step": 140
    },
    {
        "loss": 0.0459,
        "grad_norm": 0.572054922580719,
        "learning_rate": 1.812734082397004e-05,
        "epoch": 0.2808988764044944,
        "step": 150
    },
    {
        "loss": 0.046,
        "grad_norm": 0.5771273374557495,
        "learning_rate": 1.8002496878901374e-05,
        "epoch": 0.299625468164794,
        "step": 160
    },
    {
        "loss": 0.0459,
        "grad_norm": 0.725663959980011,
        "learning_rate": 1.787765293383271e-05,
        "epoch": 0.31835205992509363,
        "step": 170
    },
    {
        "loss": 0.0528,
        "grad_norm": 0.998466432094574,
        "learning_rate": 1.7752808988764045e-05,
        "epoch": 0.33707865168539325,
        "step": 180
    },
    {
        "loss": 0.0427,
        "grad_norm": 0.4984070956707001,
        "learning_rate": 1.7627965043695383e-05,
        "epoch": 0.35580524344569286,
        "step": 190
    },
    {
        "loss": 0.0426,
        "grad_norm": 0.5475485920906067,
        "learning_rate": 1.750312109862672e-05,
        "epoch": 0.37453183520599254,
        "step": 200
    },
    {
        "loss": 0.0416,
        "grad_norm": 0.3527269661426544,
        "learning_rate": 1.7378277153558054e-05,
        "epoch": 0.39325842696629215,
        "step": 210
    },
    {
        "loss": 0.0448,
        "grad_norm": 1.389054536819458,
        "learning_rate": 1.725343320848939e-05,
        "epoch": 0.41198501872659177,
        "step": 220
    },
    {
        "loss": 0.0492,
        "grad_norm": 0.5759086012840271,
        "learning_rate": 1.7128589263420725e-05,
        "epoch": 0.4307116104868914,
        "step": 230
    },
    {
        "loss": 0.0377,
        "grad_norm": 6.122335910797119,
        "learning_rate": 1.7003745318352062e-05,
        "epoch": 0.449438202247191,
        "step": 240
    },
    {
        "loss": 0.0422,
        "grad_norm": 0.38289588689804077,
        "learning_rate": 1.6878901373283396e-05,
        "epoch": 0.4681647940074906,
        "step": 250
    },
    {
        "loss": 0.051,
        "grad_norm": 0.5375739336013794,
        "learning_rate": 1.6754057428214733e-05,
        "epoch": 0.4868913857677903,
        "step": 260
    },
    {
        "loss": 0.053,
        "grad_norm": 0.7598720192909241,
        "learning_rate": 1.662921348314607e-05,
        "epoch": 0.5056179775280899,
        "step": 270
    },
    {
        "loss": 0.0485,
        "grad_norm": 0.5135094523429871,
        "learning_rate": 1.6504369538077405e-05,
        "epoch": 0.5243445692883895,
        "step": 280
    },
    {
        "loss": 0.0391,
        "grad_norm": 0.6951261162757874,
        "learning_rate": 1.6379525593008742e-05,
        "epoch": 0.5430711610486891,
        "step": 290
    },
    {
        "loss": 0.0406,
        "grad_norm": 0.4644644856452942,
        "learning_rate": 1.6254681647940076e-05,
        "epoch": 0.5617977528089888,
        "step": 300
    },
    {
        "loss": 0.0398,
        "grad_norm": 0.7059640884399414,
        "learning_rate": 1.6129837702871413e-05,
        "epoch": 0.5805243445692884,
        "step": 310
    },
    {
        "loss": 0.0522,
        "grad_norm": 0.736731767654419,
        "learning_rate": 1.6004993757802747e-05,
        "epoch": 0.599250936329588,
        "step": 320
    },
    {
        "loss": 0.0429,
        "grad_norm": 0.5931187868118286,
        "learning_rate": 1.5880149812734084e-05,
        "epoch": 0.6179775280898876,
        "step": 330
    },
    {
        "loss": 0.0407,
        "grad_norm": 0.5219604969024658,
        "learning_rate": 1.575530586766542e-05,
        "epoch": 0.6367041198501873,
        "step": 340
    },
    {
        "loss": 0.0489,
        "grad_norm": 0.7192116379737854,
        "learning_rate": 1.5630461922596755e-05,
        "epoch": 0.6554307116104869,
        "step": 350
    },
    {
        "loss": 0.0468,
        "grad_norm": 0.7240340709686279,
        "learning_rate": 1.5505617977528093e-05,
        "epoch": 0.6741573033707865,
        "step": 360
    },
    {
        "loss": 0.0419,
        "grad_norm": 0.6806139349937439,
        "learning_rate": 1.5380774032459426e-05,
        "epoch": 0.6928838951310862,
        "step": 370
    },
    {
        "loss": 0.0362,
        "grad_norm": 0.5366563200950623,
        "learning_rate": 1.5255930087390762e-05,
        "epoch": 0.7116104868913857,
        "step": 380
    },
    {
        "loss": 0.0536,
        "grad_norm": 0.40874844789505005,
        "learning_rate": 1.5131086142322098e-05,
        "epoch": 0.7303370786516854,
        "step": 390
    },
    {
        "loss": 0.0409,
        "grad_norm": 0.5204023718833923,
        "learning_rate": 1.5006242197253433e-05,
        "epoch": 0.7490636704119851,
        "step": 400
    },
    {
        "loss": 0.0498,
        "grad_norm": 9.538174629211426,
        "learning_rate": 1.488139825218477e-05,
        "epoch": 0.7677902621722846,
        "step": 410
    },
    {
        "loss": 0.034,
        "grad_norm": 0.29137545824050903,
        "learning_rate": 1.4756554307116106e-05,
        "epoch": 0.7865168539325843,
        "step": 420
    },
    {
        "loss": 0.0445,
        "grad_norm": 0.35332733392715454,
        "learning_rate": 1.4631710362047442e-05,
        "epoch": 0.8052434456928839,
        "step": 430
    },
    {
        "loss": 0.0421,
        "grad_norm": 0.32820025086402893,
        "learning_rate": 1.4506866416978777e-05,
        "epoch": 0.8239700374531835,
        "step": 440
    },
    {
        "loss": 0.0357,
        "grad_norm": 0.3104291260242462,
        "learning_rate": 1.4382022471910113e-05,
        "epoch": 0.8426966292134831,
        "step": 450
    },
    {
        "loss": 0.0502,
        "grad_norm": 0.5692030191421509,
        "learning_rate": 1.4257178526841448e-05,
        "epoch": 0.8614232209737828,
        "step": 460
    },
    {
        "loss": 0.0382,
        "grad_norm": 0.7949622869491577,
        "learning_rate": 1.4132334581772784e-05,
        "epoch": 0.8801498127340824,
        "step": 470
    },
    {
        "loss": 0.0384,
        "grad_norm": 0.4767201542854309,
        "learning_rate": 1.4007490636704121e-05,
        "epoch": 0.898876404494382,
        "step": 480
    },
    {
        "loss": 0.0344,
        "grad_norm": 0.33445751667022705,
        "learning_rate": 1.3882646691635457e-05,
        "epoch": 0.9176029962546817,
        "step": 490
    },
    {
        "loss": 0.0377,
        "grad_norm": 0.3678674101829529,
        "learning_rate": 1.3757802746566792e-05,
        "epoch": 0.9363295880149812,
        "step": 500
    },
    {
        "loss": 0.0466,
        "grad_norm": 0.3606497347354889,
        "learning_rate": 1.3632958801498128e-05,
        "epoch": 0.9550561797752809,
        "step": 510
    },
    {
        "loss": 0.0427,
        "grad_norm": 0.5676195025444031,
        "learning_rate": 1.3508114856429463e-05,
        "epoch": 0.9737827715355806,
        "step": 520
    },
    {
        "loss": 0.0411,
        "grad_norm": 0.6974966526031494,
        "learning_rate": 1.3383270911360799e-05,
        "epoch": 0.9925093632958801,
        "step": 530
    },
    {
        "eval_loss": 0.034456729888916016,
        "eval_accuracy": 0.8592870544090057,
        "eval_runtime": 5.9764,
        "eval_samples_per_second": 178.367,
        "eval_steps_per_second": 11.211,
        "epoch": 1.0,
        "step": 534
    },
    {
        "loss": 0.045,
        "grad_norm": 0.29243791103363037,
        "learning_rate": 1.3258426966292135e-05,
        "epoch": 1.0112359550561798,
        "step": 540
    },
    {
        "loss": 0.0492,
        "grad_norm": 0.4673541784286499,
        "learning_rate": 1.3133583021223472e-05,
        "epoch": 1.0299625468164795,
        "step": 550
    },
    {
        "loss": 0.0352,
        "grad_norm": 0.3311454653739929,
        "learning_rate": 1.3008739076154807e-05,
        "epoch": 1.048689138576779,
        "step": 560
    },
    {
        "loss": 0.0455,
        "grad_norm": 0.5196893811225891,
        "learning_rate": 1.2883895131086143e-05,
        "epoch": 1.0674157303370786,
        "step": 570
    },
    {
        "loss": 0.0466,
        "grad_norm": 0.5703592896461487,
        "learning_rate": 1.2759051186017479e-05,
        "epoch": 1.0861423220973783,
        "step": 580
    },
    {
        "loss": 0.0441,
        "grad_norm": 0.7798778414726257,
        "learning_rate": 1.2634207240948814e-05,
        "epoch": 1.104868913857678,
        "step": 590
    },
    {
        "loss": 0.0336,
        "grad_norm": 0.48087602853775024,
        "learning_rate": 1.250936329588015e-05,
        "epoch": 1.1235955056179776,
        "step": 600
    },
    {
        "loss": 0.0388,
        "grad_norm": 0.44544917345046997,
        "learning_rate": 1.2384519350811485e-05,
        "epoch": 1.142322097378277,
        "step": 610
    },
    {
        "loss": 0.0406,
        "grad_norm": 0.3679054379463196,
        "learning_rate": 1.2259675405742824e-05,
        "epoch": 1.1610486891385767,
        "step": 620
    },
    {
        "loss": 0.047,
        "grad_norm": 0.3796687126159668,
        "learning_rate": 1.213483146067416e-05,
        "epoch": 1.1797752808988764,
        "step": 630
    },
    {
        "loss": 0.0393,
        "grad_norm": 0.373401015996933,
        "learning_rate": 1.2009987515605494e-05,
        "epoch": 1.198501872659176,
        "step": 640
    },
    {
        "loss": 0.0438,
        "grad_norm": 0.485198050737381,
        "learning_rate": 1.188514357053683e-05,
        "epoch": 1.2172284644194757,
        "step": 650
    },
    {
        "loss": 0.042,
        "grad_norm": 0.3375083804130554,
        "learning_rate": 1.1760299625468165e-05,
        "epoch": 1.2359550561797752,
        "step": 660
    },
    {
        "loss": 0.0392,
        "grad_norm": 0.3066757917404175,
        "learning_rate": 1.16354556803995e-05,
        "epoch": 1.2546816479400749,
        "step": 670
    },
    {
        "loss": 0.0408,
        "grad_norm": 0.5613755583763123,
        "learning_rate": 1.1510611735330836e-05,
        "epoch": 1.2734082397003745,
        "step": 680
    },
    {
        "loss": 0.038,
        "grad_norm": 0.6389864683151245,
        "learning_rate": 1.1385767790262172e-05,
        "epoch": 1.2921348314606742,
        "step": 690
    },
    {
        "loss": 0.0414,
        "grad_norm": 0.9747679233551025,
        "learning_rate": 1.126092384519351e-05,
        "epoch": 1.3108614232209739,
        "step": 700
    },
    {
        "loss": 0.044,
        "grad_norm": 0.48059818148612976,
        "learning_rate": 1.1136079900124846e-05,
        "epoch": 1.3295880149812733,
        "step": 710
    },
    {
        "loss": 0.0401,
        "grad_norm": 0.5351533889770508,
        "learning_rate": 1.101123595505618e-05,
        "epoch": 1.348314606741573,
        "step": 720
    },
    {
        "loss": 0.0406,
        "grad_norm": 0.6034899353981018,
        "learning_rate": 1.0886392009987516e-05,
        "epoch": 1.3670411985018727,
        "step": 730
    },
    {
        "loss": 0.0398,
        "grad_norm": 0.3506354093551636,
        "learning_rate": 1.0761548064918851e-05,
        "epoch": 1.3857677902621723,
        "step": 740
    },
    {
        "loss": 0.0392,
        "grad_norm": 0.38930103182792664,
        "learning_rate": 1.0636704119850187e-05,
        "epoch": 1.404494382022472,
        "step": 750
    },
    {
        "loss": 0.0385,
        "grad_norm": 0.4049871563911438,
        "learning_rate": 1.0511860174781522e-05,
        "epoch": 1.4232209737827715,
        "step": 760
    },
    {
        "loss": 0.0379,
        "grad_norm": 0.4534943401813507,
        "learning_rate": 1.0387016229712861e-05,
        "epoch": 1.4419475655430711,
        "step": 770
    },
    {
        "loss": 0.0411,
        "grad_norm": 0.42219942808151245,
        "learning_rate": 1.0262172284644197e-05,
        "epoch": 1.4606741573033708,
        "step": 780
    },
    {
        "loss": 0.0424,
        "grad_norm": 0.722686767578125,
        "learning_rate": 1.0137328339575533e-05,
        "epoch": 1.4794007490636705,
        "step": 790
    },
    {
        "loss": 0.0437,
        "grad_norm": 0.4560951888561249,
        "learning_rate": 1.0012484394506868e-05,
        "epoch": 1.4981273408239701,
        "step": 800
    },
    {
        "loss": 0.0412,
        "grad_norm": 0.6447272300720215,
        "learning_rate": 9.887640449438202e-06,
        "epoch": 1.5168539325842696,
        "step": 810
    },
    {
        "loss": 0.0398,
        "grad_norm": 0.8966709971427917,
        "learning_rate": 9.76279650436954e-06,
        "epoch": 1.5355805243445693,
        "step": 820
    },
    {
        "loss": 0.0412,
        "grad_norm": 0.24326902627944946,
        "learning_rate": 9.637952559300875e-06,
        "epoch": 1.554307116104869,
        "step": 830
    },
    {
        "loss": 0.0461,
        "grad_norm": 0.45347490906715393,
        "learning_rate": 9.51310861423221e-06,
        "epoch": 1.5730337078651684,
        "step": 840
    },
    {
        "loss": 0.0436,
        "grad_norm": 0.8133862614631653,
        "learning_rate": 9.388264669163546e-06,
        "epoch": 1.5917602996254683,
        "step": 850
    },
    {
        "loss": 0.0428,
        "grad_norm": 0.3252224028110504,
        "learning_rate": 9.263420724094883e-06,
        "epoch": 1.6104868913857677,
        "step": 860
    },
    {
        "loss": 0.0435,
        "grad_norm": 0.3784102499485016,
        "learning_rate": 9.138576779026219e-06,
        "epoch": 1.6292134831460674,
        "step": 870
    },
    {
        "loss": 0.037,
        "grad_norm": 0.6171584725379944,
        "learning_rate": 9.013732833957554e-06,
        "epoch": 1.647940074906367,
        "step": 880
    },
    {
        "loss": 0.0474,
        "grad_norm": 0.46909427642822266,
        "learning_rate": 8.888888888888888e-06,
        "epoch": 1.6666666666666665,
        "step": 890
    },
    {
        "loss": 0.0387,
        "grad_norm": 0.3567160665988922,
        "learning_rate": 8.764044943820226e-06,
        "epoch": 1.6853932584269664,
        "step": 900
    },
    {
        "loss": 0.0334,
        "grad_norm": 0.597309410572052,
        "learning_rate": 8.639200998751561e-06,
        "epoch": 1.7041198501872659,
        "step": 910
    },
    {
        "loss": 0.0397,
        "grad_norm": 0.5106911063194275,
        "learning_rate": 8.514357053682897e-06,
        "epoch": 1.7228464419475655,
        "step": 920
    },
    {
        "loss": 0.0334,
        "grad_norm": 0.8464896082878113,
        "learning_rate": 8.389513108614234e-06,
        "epoch": 1.7415730337078652,
        "step": 930
    },
    {
        "loss": 0.0388,
        "grad_norm": 0.43400079011917114,
        "learning_rate": 8.26466916354557e-06,
        "epoch": 1.7602996254681647,
        "step": 940
    },
    {
        "loss": 0.0361,
        "grad_norm": 0.44127556681632996,
        "learning_rate": 8.139825218476905e-06,
        "epoch": 1.7790262172284645,
        "step": 950
    },
    {
        "loss": 0.0423,
        "grad_norm": 0.6580122709274292,
        "learning_rate": 8.01498127340824e-06,
        "epoch": 1.797752808988764,
        "step": 960
    },
    {
        "loss": 0.036,
        "grad_norm": 0.5613852739334106,
        "learning_rate": 7.890137328339576e-06,
        "epoch": 1.8164794007490637,
        "step": 970
    },
    {
        "loss": 0.0398,
        "grad_norm": 0.4655390679836273,
        "learning_rate": 7.765293383270912e-06,
        "epoch": 1.8352059925093633,
        "step": 980
    },
    {
        "loss": 0.0447,
        "grad_norm": 0.43038371205329895,
        "learning_rate": 7.640449438202247e-06,
        "epoch": 1.8539325842696628,
        "step": 990
    },
    {
        "loss": 0.0343,
        "grad_norm": 0.2929370701313019,
        "learning_rate": 7.515605493133583e-06,
        "epoch": 1.8726591760299627,
        "step": 1000
    },
    {
        "loss": 0.0443,
        "grad_norm": 0.5586252808570862,
        "learning_rate": 7.3907615480649195e-06,
        "epoch": 1.8913857677902621,
        "step": 1010
    },
    {
        "loss": 0.0497,
        "grad_norm": 0.7142296433448792,
        "learning_rate": 7.265917602996255e-06,
        "epoch": 1.9101123595505618,
        "step": 1020
    },
    {
        "loss": 0.0321,
        "grad_norm": 0.6825270652770996,
        "learning_rate": 7.141073657927591e-06,
        "epoch": 1.9288389513108615,
        "step": 1030
    },
    {
        "loss": 0.0447,
        "grad_norm": 0.8538267612457275,
        "learning_rate": 7.016229712858927e-06,
        "epoch": 1.947565543071161,
        "step": 1040
    },
    {
        "loss": 0.0373,
        "grad_norm": 0.513683021068573,
        "learning_rate": 6.891385767790263e-06,
        "epoch": 1.9662921348314608,
        "step": 1050
    },
    {
        "loss": 0.0352,
        "grad_norm": 0.5281947255134583,
        "learning_rate": 6.766541822721598e-06,
        "epoch": 1.9850187265917603,
        "step": 1060
    },
    {
        "eval_loss": 0.03335241228342056,
        "eval_accuracy": 0.8630393996247655,
        "eval_runtime": 6.2456,
        "eval_samples_per_second": 170.679,
        "eval_steps_per_second": 10.727,
        "epoch": 2.0,
        "step": 1068
    },
    {
        "loss": 0.0393,
        "grad_norm": 0.6998339295387268,
        "learning_rate": 6.641697877652934e-06,
        "epoch": 2.0037453183520597,
        "step": 1070
    },
    {
        "loss": 0.0313,
        "grad_norm": 0.4076150059700012,
        "learning_rate": 6.51685393258427e-06,
        "epoch": 2.0224719101123596,
        "step": 1080
    },
    {
        "loss": 0.0395,
        "grad_norm": 0.6746863722801208,
        "learning_rate": 6.392009987515606e-06,
        "epoch": 2.041198501872659,
        "step": 1090
    },
    {
        "loss": 0.0405,
        "grad_norm": 0.870652973651886,
        "learning_rate": 6.267166042446941e-06,
        "epoch": 2.059925093632959,
        "step": 1100
    },
    {
        "loss": 0.0459,
        "grad_norm": 0.4963259994983673,
        "learning_rate": 6.142322097378277e-06,
        "epoch": 2.0786516853932584,
        "step": 1110
    },
    {
        "loss": 0.0389,
        "grad_norm": 0.36088234186172485,
        "learning_rate": 6.017478152309613e-06,
        "epoch": 2.097378277153558,
        "step": 1120
    },
    {
        "loss": 0.0375,
        "grad_norm": 0.3753620982170105,
        "learning_rate": 5.892634207240949e-06,
        "epoch": 2.1161048689138577,
        "step": 1130
    },
    {
        "loss": 0.0367,
        "grad_norm": 0.3628373444080353,
        "learning_rate": 5.7677902621722845e-06,
        "epoch": 2.134831460674157,
        "step": 1140
    },
    {
        "loss": 0.0374,
        "grad_norm": 0.4446091949939728,
        "learning_rate": 5.642946317103622e-06,
        "epoch": 2.153558052434457,
        "step": 1150
    },
    {
        "loss": 0.0358,
        "grad_norm": 0.34532707929611206,
        "learning_rate": 5.5181023720349565e-06,
        "epoch": 2.1722846441947565,
        "step": 1160
    },
    {
        "loss": 0.0411,
        "grad_norm": 0.6226524710655212,
        "learning_rate": 5.393258426966292e-06,
        "epoch": 2.191011235955056,
        "step": 1170
    },
    {
        "loss": 0.0314,
        "grad_norm": 0.3811264634132385,
        "learning_rate": 5.268414481897628e-06,
        "epoch": 2.209737827715356,
        "step": 1180
    },
    {
        "loss": 0.0367,
        "grad_norm": 0.49432772397994995,
        "learning_rate": 5.143570536828965e-06,
        "epoch": 2.2284644194756553,
        "step": 1190
    },
    {
        "loss": 0.0438,
        "grad_norm": 0.4376309812068939,
        "learning_rate": 5.0187265917603005e-06,
        "epoch": 2.247191011235955,
        "step": 1200
    },
    {
        "loss": 0.0362,
        "grad_norm": 0.3613818883895874,
        "learning_rate": 4.893882646691635e-06,
        "epoch": 2.2659176029962547,
        "step": 1210
    },
    {
        "loss": 0.0358,
        "grad_norm": 0.23709437251091003,
        "learning_rate": 4.769038701622972e-06,
        "epoch": 2.284644194756554,
        "step": 1220
    },
    {
        "loss": 0.0456,
        "grad_norm": 0.41130968928337097,
        "learning_rate": 4.644194756554308e-06,
        "epoch": 2.303370786516854,
        "step": 1230
    },
    {
        "loss": 0.0379,
        "grad_norm": 0.24205274879932404,
        "learning_rate": 4.519350811485644e-06,
        "epoch": 2.3220973782771535,
        "step": 1240
    },
    {
        "loss": 0.0473,
        "grad_norm": 0.7285028100013733,
        "learning_rate": 4.394506866416979e-06,
        "epoch": 2.3408239700374533,
        "step": 1250
    },
    {
        "loss": 0.0342,
        "grad_norm": 0.40989255905151367,
        "learning_rate": 4.269662921348315e-06,
        "epoch": 2.359550561797753,
        "step": 1260
    },
    {
        "loss": 0.0391,
        "grad_norm": 0.4762534499168396,
        "learning_rate": 4.144818976279651e-06,
        "epoch": 2.3782771535580522,
        "step": 1270
    },
    {
        "loss": 0.0452,
        "grad_norm": 0.7377206087112427,
        "learning_rate": 4.019975031210987e-06,
        "epoch": 2.397003745318352,
        "step": 1280
    },
    {
        "loss": 0.038,
        "grad_norm": 0.5619133710861206,
        "learning_rate": 3.895131086142322e-06,
        "epoch": 2.4157303370786516,
        "step": 1290
    },
    {
        "loss": 0.0308,
        "grad_norm": 0.2235032618045807,
        "learning_rate": 3.770287141073658e-06,
        "epoch": 2.4344569288389515,
        "step": 1300
    },
    {
        "loss": 0.0383,
        "grad_norm": 0.4647233486175537,
        "learning_rate": 3.645443196004994e-06,
        "epoch": 2.453183520599251,
        "step": 1310
    },
    {
        "loss": 0.044,
        "grad_norm": 0.6204347610473633,
        "learning_rate": 3.52059925093633e-06,
        "epoch": 2.4719101123595504,
        "step": 1320
    },
    {
        "loss": 0.0359,
        "grad_norm": 0.3551924228668213,
        "learning_rate": 3.3957553058676655e-06,
        "epoch": 2.4906367041198503,
        "step": 1330
    },
    {
        "loss": 0.0357,
        "grad_norm": 0.3807322680950165,
        "learning_rate": 3.2709113607990015e-06,
        "epoch": 2.5093632958801497,
        "step": 1340
    },
    {
        "loss": 0.0342,
        "grad_norm": 0.2662109434604645,
        "learning_rate": 3.146067415730337e-06,
        "epoch": 2.5280898876404496,
        "step": 1350
    },
    {
        "loss": 0.0351,
        "grad_norm": 0.3387158215045929,
        "learning_rate": 3.021223470661673e-06,
        "epoch": 2.546816479400749,
        "step": 1360
    },
    {
        "loss": 0.0334,
        "grad_norm": 0.25483351945877075,
        "learning_rate": 2.8963795255930087e-06,
        "epoch": 2.5655430711610485,
        "step": 1370
    },
    {
        "loss": 0.031,
        "grad_norm": 0.37834644317626953,
        "learning_rate": 2.771535580524345e-06,
        "epoch": 2.5842696629213484,
        "step": 1380
    },
    {
        "loss": 0.0366,
        "grad_norm": 0.310067355632782,
        "learning_rate": 2.6466916354556803e-06,
        "epoch": 2.602996254681648,
        "step": 1390
    },
    {
        "loss": 0.0348,
        "grad_norm": 0.5041916966438293,
        "learning_rate": 2.5218476903870167e-06,
        "epoch": 2.6217228464419478,
        "step": 1400
    },
    {
        "loss": 0.0331,
        "grad_norm": 0.4052112102508545,
        "learning_rate": 2.3970037453183523e-06,
        "epoch": 2.640449438202247,
        "step": 1410
    },
    {
        "loss": 0.0425,
        "grad_norm": 0.5463093519210815,
        "learning_rate": 2.2721598002496883e-06,
        "epoch": 2.6591760299625467,
        "step": 1420
    },
    {
        "loss": 0.0339,
        "grad_norm": 0.4804886281490326,
        "learning_rate": 2.147315855181024e-06,
        "epoch": 2.6779026217228465,
        "step": 1430
    },
    {
        "loss": 0.0382,
        "grad_norm": 0.3932841420173645,
        "learning_rate": 2.02247191011236e-06,
        "epoch": 2.696629213483146,
        "step": 1440
    },
    {
        "loss": 0.0419,
        "grad_norm": 0.9126854538917542,
        "learning_rate": 1.8976279650436954e-06,
        "epoch": 2.715355805243446,
        "step": 1450
    },
    {
        "loss": 0.0359,
        "grad_norm": 0.318379670381546,
        "learning_rate": 1.7727840199750312e-06,
        "epoch": 2.7340823970037453,
        "step": 1460
    },
    {
        "loss": 0.0434,
        "grad_norm": 0.2254381626844406,
        "learning_rate": 1.647940074906367e-06,
        "epoch": 2.752808988764045,
        "step": 1470
    },
    {
        "loss": 0.0363,
        "grad_norm": 0.38489556312561035,
        "learning_rate": 1.5230961298377032e-06,
        "epoch": 2.7715355805243447,
        "step": 1480
    },
    {
        "loss": 0.039,
        "grad_norm": 0.354870080947876,
        "learning_rate": 1.398252184769039e-06,
        "epoch": 2.790262172284644,
        "step": 1490
    },
    {
        "loss": 0.0464,
        "grad_norm": 0.5260334014892578,
        "learning_rate": 1.2734082397003748e-06,
        "epoch": 2.808988764044944,
        "step": 1500
    },
    {
        "loss": 0.0354,
        "grad_norm": 0.4191032946109772,
        "learning_rate": 1.1485642946317106e-06,
        "epoch": 2.8277153558052435,
        "step": 1510
    },
    {
        "loss": 0.033,
        "grad_norm": 0.22385452687740326,
        "learning_rate": 1.0237203495630464e-06,
        "epoch": 2.846441947565543,
        "step": 1520
    },
    {
        "loss": 0.0347,
        "grad_norm": 0.345944881439209,
        "learning_rate": 8.98876404494382e-07,
        "epoch": 2.865168539325843,
        "step": 1530
    },
    {
        "loss": 0.035,
        "grad_norm": 0.3186757564544678,
        "learning_rate": 7.740324594257178e-07,
        "epoch": 2.8838951310861423,
        "step": 1540
    },
    {
        "loss": 0.0398,
        "grad_norm": 0.42052382230758667,
        "learning_rate": 6.491885143570538e-07,
        "epoch": 2.902621722846442,
        "step": 1550
    },
    {
        "loss": 0.0347,
        "grad_norm": 0.452220618724823,
        "learning_rate": 5.243445692883896e-07,
        "epoch": 2.9213483146067416,
        "step": 1560
    },
    {
        "loss": 0.0446,
        "grad_norm": 0.647533655166626,
        "learning_rate": 3.9950062421972536e-07,
        "epoch": 2.940074906367041,
        "step": 1570
    },
    {
        "loss": 0.0347,
        "grad_norm": 0.4515148997306824,
        "learning_rate": 2.746566791510612e-07,
        "epoch": 2.958801498127341,
        "step": 1580
    },
    {
        "loss": 0.0345,
        "grad_norm": 0.3946172297000885,
        "learning_rate": 1.4981273408239702e-07,
        "epoch": 2.9775280898876404,
        "step": 1590
    },
    {
        "loss": 0.0382,
        "grad_norm": 0.5916827917098999,
        "learning_rate": 2.4968789013732835e-08,
        "epoch": 2.9962546816479403,
        "step": 1600
    },
    {
        "eval_loss": 0.03323906287550926,
        "eval_accuracy": 0.8667917448405253,
        "eval_runtime": 6.565,
        "eval_samples_per_second": 162.377,
        "eval_steps_per_second": 10.206,
        "epoch": 3.0,
        "step": 1602
    },
    {
        "train_runtime": 322.1352,
        "train_samples_per_second": 79.439,
        "train_steps_per_second": 4.973,
        "total_flos": 865849174917120.0,
        "train_loss": 0.10295054988096121,
        "epoch": 3.0,
        "step": 1602
    }
]