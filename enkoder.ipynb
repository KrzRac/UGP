{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KrzRac/UGP/blob/main/enkoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KczkHBxaaoz"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "fOxTetc9Zd-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive_results_dir = \"/content/drive/MyDrive/roberta_results\"\n",
        "os.makedirs(drive_results_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "U-SrAgoWiOAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"rotten_tomatoes\")"
      ],
      "metadata": {
        "id": "ZIyTJcvvaOwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['text'], truncation=True, padding=True, max_length=128)"
      ],
      "metadata": {
        "id": "VFwP-rvoaTdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "tokenized_datasets = dataset.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "id": "ot1CveG8bpuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_datasets)"
      ],
      "metadata": {
        "id": "gbBqhF-ObyPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tokenized_datasets[\"train\"]\n",
        "valid_dataset = tokenized_datasets[\"validation\"]\n",
        "test_dataset = tokenized_datasets[\"test\"]"
      ],
      "metadata": {
        "id": "HuLZbIqubt33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)"
      ],
      "metadata": {
        "id": "03SUtpmab6YF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frozen_layer_count = 4  # Number of encoder layers to freeze\n",
        "for name, param in model.named_parameters():\n",
        "    if \"embeddings\" in name or any(f\"layer.{i}.\" in name for i in range(frozen_layer_count)):\n",
        "        param.requires_grad = False"
      ],
      "metadata": {
        "id": "ju0r6FYRb_o7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"RobertaForSequenceClassification:\")\n",
        "print(model)\n",
        "frozen_layers = [name for name, param in model.named_parameters() if not param.requires_grad]\n",
        "print(\"Frozen layers:\", frozen_layers)"
      ],
      "metadata": {
        "id": "bhNGrpk4cByb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    return {\"accuracy\": acc}"
      ],
      "metadata": {
        "id": "CW6C8ot6cO5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=drive_results_dir,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=drive_results_dir,\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=valid_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "013UU5uicR5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training RobertaForSequenceClassification...\")\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "0ch91WhHcZri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_results = trainer.evaluate(test_dataset)\n",
        "\n",
        "eval_results_file = os.path.join(drive_results_dir, \"eval_results.txt\")\n",
        "with open(eval_results_file, \"w\") as f:\n",
        "    f.write(str(eval_results))\n",
        "\n",
        "print(f\"Evaluation results saved at: {eval_results_file}\")\n",
        "\n",
        "print(\"Evaluation results:\", eval_results)"
      ],
      "metadata": {
        "id": "J3P6FO3FcfYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Generating detailed evaluation report...\")\n",
        "logits, labels = trainer.predict(test_dataset)[:2]\n",
        "predictions = np.argmax(logits, axis=-1)\n",
        "report = classification_report(labels, predictions, target_names=[\"negative\", \"positive\"], digits=4)\n",
        "\n",
        "classification_report_file = os.path.join(drive_results_dir, \"classification_report.txt\")\n",
        "with open(classification_report_file, \"w\") as f:\n",
        "    f.write(report)\n",
        "\n",
        "print(f\"Classification report saved at: {classification_report_file}\")\n",
        "\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "id": "TF5CHF2_ci4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = os.path.join(drive_results_dir, \"roberta_finetuned\")\n",
        "tokenizer_save_path = os.path.join(drive_results_dir, \"roberta_finetuned_tokenizer\")\n",
        "\n",
        "model.save_pretrained(model_save_path)\n",
        "tokenizer.save_pretrained(tokenizer_save_path)\n",
        "\n",
        "print(f\"Model saved at: {model_save_path}\")\n",
        "print(f\"Tokenizer saved at: {tokenizer_save_path}\")"
      ],
      "metadata": {
        "id": "NQUSs0O9ckcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = test_dataset['text'][:3]\n",
        "\n",
        "tokens = tokenizer(examples, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "# Ensure the model and data are on the same device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "tokens = {key: val.to(device) for key, val in tokens.items()}\n",
        "\n",
        "# Get predictions\n",
        "outputs = model(**tokens)\n",
        "predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "print(\"Predictions:\")\n",
        "for i, example in enumerate(examples):\n",
        "    print(f\"Review: {example}\")\n",
        "    print(f\"Predicted sentiment: {'positive' if predictions[i] == 1 else 'negative'}\")\n"
      ],
      "metadata": {
        "id": "JOxjMIRTUNPj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOoQpw3zNQ7wQmDVafpx8nC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}